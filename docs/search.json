[
  {
    "objectID": "slides/3-convolutions.html#section",
    "href": "slides/3-convolutions.html#section",
    "title": "DAT255: Deep learning engineering",
    "section": "",
    "text": "TensorFlowplayground"
  },
  {
    "objectID": "slides/3-convolutions.html#shallow-learning",
    "href": "slides/3-convolutions.html#shallow-learning",
    "title": "DAT255: Deep learning engineering",
    "section": "Shallow learning",
    "text": "Shallow learning\n\n\n\n\n\n\n%%{ init: {'flowchart': { 'curve': 'bumpX', 'nodeSpacing': 50, 'rankSpacing': 80 } } }%%\nflowchart LR\n    X1(\"x1\") --&gt; M{Model}\n    X2(\"x2\") --&gt; M\n    X1 --&gt; X3(\"x3\")\n    X2 --&gt; X3\n    X1 --&gt; X4(\"x4\")\n    X2 --&gt; X4\n    X3 --&gt; M\n    X4 --&gt; M\n    subgraph ML\n    M\n    end\n    subgraph F[Original features]\n    X1\n    X2\n    end\n    subgraph FE[Engineered features]\n    X3\n    X4\n    end \n    M --&gt; P(\"Prediction _y_\")\n\nstyle ML fill:#ededed,stroke:#606060\nstyle F fill:#ededed,stroke:#606060\nstyle FE fill:#FFF8E1,stroke:#606060\n\n\n\n\n\n\n\n\\[\ny = f(x_1, x_2, x_3, x_4, \\dots, x_n | \\theta)\n\\]"
  },
  {
    "objectID": "slides/3-convolutions.html#deep-learning",
    "href": "slides/3-convolutions.html#deep-learning",
    "title": "DAT255: Deep learning engineering",
    "section": "Deep learning",
    "text": "Deep learning\n\n\n\n\n\n\n%%{ init: {'flowchart': { 'curve': 'bumpX', 'nodeSpacing': 50, 'rankSpacing': 80 } } }%%\nflowchart LR\n    X1(\"x1\") --&gt; L1(Layer 1)\n    X2(\"x2\") --&gt; L1\n    subgraph ML[Neural network]\n    L1 --&gt; L2(Layer 2)\n    L2 --&gt; L3(Layer 3)\n    end\n    subgraph F[Original features]\n    X1\n    X2\n    end\n    L3 --&gt; P(\"Prediction _y_\")\n\nstyle ML fill:#ededed,stroke:#606060\nstyle F fill:#ededed,stroke:#606060\n\n\n\n\n\n\n\n\\[\ny = f_3(f_2(f_1(x_1, x_2 | \\theta_1) | \\theta_2) | \\theta_3)\n\\]"
  },
  {
    "objectID": "slides/3-convolutions.html#section-1",
    "href": "slides/3-convolutions.html#section-1",
    "title": "DAT255: Deep learning engineering",
    "section": "",
    "text": "TensorFlowplayground"
  },
  {
    "objectID": "slides/3-convolutions.html#deep-learning-1",
    "href": "slides/3-convolutions.html#deep-learning-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Deep learning",
    "text": "Deep learning\n\n\n\nThe point of deep learning is to sequentially learn better feature representations, and use these to solve a task.\n\n\n\nSince neural networks are universal function approximators, they can model arbitrarily complex relationships. The cost of doing so, is that we need a lot of data."
  },
  {
    "objectID": "slides/3-convolutions.html#the-feed-forward-neural-network",
    "href": "slides/3-convolutions.html#the-feed-forward-neural-network",
    "title": "DAT255: Deep learning engineering",
    "section": "The feed-forward neural network",
    "text": "The feed-forward neural network\nFor the demo we used the good olâ€™ fully-connected feed-forward network:\n\n\n\n\nEach node computes an output by\n\\[\n\\small\ny = f\\left( \\sum_{i=1}^{n} w_ix_i + b \\right)\n\\]\nwhere\n\n\\(w_i\\) is the weight of each incoming connection\n\\(b\\) is the bias term\n\\(f\\) is the activation function (more next week)"
  },
  {
    "objectID": "slides/3-convolutions.html#image-classification",
    "href": "slides/3-convolutions.html#image-classification",
    "title": "DAT255: Deep learning engineering",
    "section": "Image classification",
    "text": "Image classification\nLetâ€™s classify this image: (see notebook 1)"
  },
  {
    "objectID": "slides/3-convolutions.html#image-classification-1",
    "href": "slides/3-convolutions.html#image-classification-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Image classification",
    "text": "Image classification\nLetâ€™s classify this image: (see notebook 1)\nTry to treat every pixel as feature:\n\n\n2"
  },
  {
    "objectID": "slides/3-convolutions.html#image-classification-2",
    "href": "slides/3-convolutions.html#image-classification-2",
    "title": "DAT255: Deep learning engineering",
    "section": "Image classification",
    "text": "Image classification\nLetâ€™s classify this image: (see notebook 1)\nTry to treat every pixel as feature:\n\n\nnot 2\n\n\nTwo obvious problems:\n\nNot invariant under translation(move the image  different result)\nNot invariant under dilation(resize the image  different result)"
  },
  {
    "objectID": "slides/3-convolutions.html#enter-the-convolution-operation",
    "href": "slides/3-convolutions.html#enter-the-convolution-operation",
    "title": "DAT255: Deep learning engineering",
    "section": "Enter the convolution operation",
    "text": "Enter the convolution operation\nThe foundation for modern computer vision (plus lots of other things!) is convolution:\nan operation that takes in two functions and returns a new function\n\n\n\n\n\n\\[\nf \\ast g \\equiv \\int_{-\\infty}^{\\infty} f(\\tau) g(t-\\tau) d\\tau\n\\]"
  },
  {
    "objectID": "slides/3-convolutions.html#enter-the-convolution-operation-1",
    "href": "slides/3-convolutions.html#enter-the-convolution-operation-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Enter the convolution operation",
    "text": "Enter the convolution operation\nThe foundation for modern computer vision (plus lots of other things!) is convolution:\nan operation that takes in two functions and returns a new function\n\n\n\n\n\n\\[\nf \\ast g \\equiv \\int_{-\\infty}^{\\infty} f(\\tau) g(t-\\tau) d\\tau\n\\]\n\n\n\nIn practice, convolution is a way to recognise and localise patterns in data"
  },
  {
    "objectID": "slides/3-convolutions.html#discrete-convolution",
    "href": "slides/3-convolutions.html#discrete-convolution",
    "title": "DAT255: Deep learning engineering",
    "section": "Discrete convolution",
    "text": "Discrete convolution\nConvolution is a lot easier with discrete data such as images, because:\n\nthe integral becomes a sum\nthe first function is our image\nthe second function is our kernel, which tries to find patters in the image."
  },
  {
    "objectID": "slides/3-convolutions.html#convolution-over-images",
    "href": "slides/3-convolutions.html#convolution-over-images",
    "title": "DAT255: Deep learning engineering",
    "section": "Convolution over images",
    "text": "Convolution over images\nSimple case â€“ one input channel"
  },
  {
    "objectID": "slides/3-convolutions.html#convolution-over-images-1",
    "href": "slides/3-convolutions.html#convolution-over-images-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Convolution over images",
    "text": "Convolution over images\nFor RGB color images: Process each color channel, then sum"
  },
  {
    "objectID": "slides/3-convolutions.html#the-convolution-kernel-or-filter",
    "href": "slides/3-convolutions.html#the-convolution-kernel-or-filter",
    "title": "DAT255: Deep learning engineering",
    "section": "The convolution kernel (or filter)",
    "text": "The convolution kernel (or filter)\nConvolution with predefined kernels is the core to digital image processing (but then we call it filters)\n\n\n\n\n\n\n\n\n\nIdentify vertical lines\n\n\n\n\n\n\n\nIdentify diagonal lines\n\n\n\n\n\n\n\nIdentifiy horizontal lines"
  },
  {
    "objectID": "slides/3-convolutions.html#more-filters",
    "href": "slides/3-convolutions.html#more-filters",
    "title": "DAT255: Deep learning engineering",
    "section": "More filters",
    "text": "More filters\n\n\nAverage: blurring effect\n\n\n\n\n\n\n\n\nSobel filter: Edge detector"
  },
  {
    "objectID": "slides/3-convolutions.html#kernels-for-image-recognition",
    "href": "slides/3-convolutions.html#kernels-for-image-recognition",
    "title": "DAT255: Deep learning engineering",
    "section": "Kernels for image recognition",
    "text": "Kernels for image recognition\nLetâ€™s try handcrafting some filters/kernels:\n\n\n\n\n\n\n\n\n\n\n\nNeed to refinethe approach :/"
  },
  {
    "objectID": "slides/3-convolutions.html#decomposition-into-simple-patters",
    "href": "slides/3-convolutions.html#decomposition-into-simple-patters",
    "title": "DAT255: Deep learning engineering",
    "section": "Decomposition into simple patters",
    "text": "Decomposition into simple patters\nA better approach: Multiple small filters\n\n\n\n\n\n\nOriginal image\n\n\nNew image, in lower resolution\n\n\nRepeat"
  },
  {
    "objectID": "slides/3-convolutions.html#decomposition-into-simple-patters-1",
    "href": "slides/3-convolutions.html#decomposition-into-simple-patters-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Decomposition into simple patters",
    "text": "Decomposition into simple patters"
  },
  {
    "objectID": "slides/3-convolutions.html#section-2",
    "href": "slides/3-convolutions.html#section-2",
    "title": "DAT255: Deep learning engineering",
    "section": "",
    "text": "Talk is cheap.Show me the code"
  },
  {
    "objectID": "slides/3-convolutions.html#keras-layers",
    "href": "slides/3-convolutions.html#keras-layers",
    "title": "DAT255: Deep learning engineering",
    "section": "Keras layers",
    "text": "Keras layers\nFor our proposed solution we need three layer types:\n\n\n\n\nConvolution layers to extract image features\nkeras.layers.Conv2D\n\n\n\n\n\nPooling layers to downsample and aggregate the features\nkeras.layers.MaxPooling2D\n\n\n\n\n\nFully-connected (dense) layers to compute the final prediction\nkeras.layers.Dense"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer",
    "href": "slides/3-convolutions.html#the-conv2d-layer",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer-1",
    "href": "slides/3-convolutions.html#the-conv2d-layer-1",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n\nNumber of filters to use (typical: 32 to 512)"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer-2",
    "href": "slides/3-convolutions.html#the-conv2d-layer-2",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n\nSize of the filter/kernel (typical: 3x3, sometimes bigger in the first layer)"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer-3",
    "href": "slides/3-convolutions.html#the-conv2d-layer-3",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n\nStepsize for the convolution operation (typical: 1 or 2)\n\n\n\n\n\n\n\n\n\nstride=(1,1)\n\n\n\n\n\n\n\n\n\nstride=(2,2)"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer-4",
    "href": "slides/3-convolutions.html#the-conv2d-layer-4",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n\nPadding around the image edges (typical: 1 or 2)\n\n\n\n\n\n\n\n\n\npadding=\"valid\"\n\n\n\n\n\n\n\n\n\npadding=\"same\""
  },
  {
    "objectID": "slides/3-convolutions.html#pooling-layers",
    "href": "slides/3-convolutions.html#pooling-layers",
    "title": "DAT255: Deep learning engineering",
    "section": "Pooling layers",
    "text": "Pooling layers\nTwo reasons for downsampling the image features:\n\nLearn a spatial hierarchy by widening the receptive field\nReduce the total parameter count\n\nMost common approach: Choose the maximum value from a window of pixels"
  },
  {
    "objectID": "slides/3-convolutions.html#the-maxpooling2d-layer",
    "href": "slides/3-convolutions.html#the-maxpooling2d-layer",
    "title": "DAT255: Deep learning engineering",
    "section": "The MaxPooling2D layer",
    "text": "The MaxPooling2D layer\n\n\nkeras.layers.MaxPooling2D(\n    pool_size=(2, 2),\n    strides=None,\n    padding=\"valid\",\n    data_format=None, \n    name=None, \n    **kwargs\n)\n\npool_size: Size of pooling window (typical: 2x2 or 3x3)\nstrides: Step size (typical: same as pool_size)\npadding: Padding around edges, valid or same"
  },
  {
    "objectID": "slides/3-convolutions.html#the-dense-layer",
    "href": "slides/3-convolutions.html#the-dense-layer",
    "title": "DAT255: Deep learning engineering",
    "section": "The Dense layer",
    "text": "The Dense layer\n\n\nkeras.layers.Dense(\n    units,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    lora_rank=None,\n    **kwargs\n)\n\nunits: number of nodes in this layer\n\n\n\n\n\n\nIn the last dense layer, units must be equal to the number of classes (or otherwise number of desired outputs)."
  },
  {
    "objectID": "slides/3-convolutions.html#my-first-convolutional-network",
    "href": "slides/3-convolutions.html#my-first-convolutional-network",
    "title": "DAT255: Deep learning engineering",
    "section": "My first convolutional network âœ¨",
    "text": "My first convolutional network âœ¨\nLetâ€™s piece together a convnet using Kerasâ€™ sequential model API:\n\n\n\nconvnet = keras.Sequential(\n    [\n        keras.Input(shape=(28, 28, 1)),\n        keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        keras.layers.Flatten(),\n        keras.layers.Dense(10, activation=\"softmax\"),\n    ]\n)\n\n\n\n(More details about activations and training next week)"
  },
  {
    "objectID": "slides/3-convolutions.html#my-first-convolutional-network-1",
    "href": "slides/3-convolutions.html#my-first-convolutional-network-1",
    "title": "DAT255: Deep learning engineering",
    "section": "My first convolutional network âœ¨",
    "text": "My first convolutional network âœ¨\nconvnet.summary()\nModel: \"sequential_1\"\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ conv2d (Conv2D)                      â”‚ (None, 26, 26, 32)          â”‚             320 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d (MaxPooling2D)         â”‚ (None, 13, 13, 32)          â”‚               0 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_1 (Conv2D)                    â”‚ (None, 11, 11, 32)          â”‚           9,248 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_1 (MaxPooling2D)       â”‚ (None, 5, 5, 32)            â”‚               0 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_1 (Flatten)                  â”‚ (None, 800)                 â”‚               0 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (Dropout)                    â”‚ (None, 800)                 â”‚               0 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_3 (Dense)                      â”‚ (None, 10)                  â”‚           8,010 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n Total params: 17,578 (68.66 KB)\n\n Trainable params: 17,578 (68.66 KB)\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "slides/3-convolutions.html#my-first-convolutional-network-2",
    "href": "slides/3-convolutions.html#my-first-convolutional-network-2",
    "title": "DAT255: Deep learning engineering",
    "section": "My first convolutional network âœ¨",
    "text": "My first convolutional network âœ¨\nConfigure the training objective and strategy:\nconvnet.compile(\n  loss=\"categorical_crossentropy\",\n  optimizer=\"adam\",\n  metrics=[\"accuracy\"]\n)\n(again, more details next week)\nStart training!\nconvnet.fit(\n  X_train,\n  y_train,\n  batch_size=128,\n  epochs=15,\n  validation_split=0.1\n)"
  },
  {
    "objectID": "slides/3-convolutions.html#pre-trained-models",
    "href": "slides/3-convolutions.html#pre-trained-models",
    "title": "DAT255: Deep learning engineering",
    "section": "Pre-trained models",
    "text": "Pre-trained models"
  },
  {
    "objectID": "slides/3-convolutions.html#decomposition-into-simple-patters-theory-vs-practice",
    "href": "slides/3-convolutions.html#decomposition-into-simple-patters-theory-vs-practice",
    "title": "DAT255: Deep learning engineering",
    "section": "Decomposition into simple patters: Theory vs practice",
    "text": "Decomposition into simple patters: Theory vs practice\nRemember the cat:\n\n\n\n\n\n(Weâ€™ll try to classify pictures of cats in exercise 3, but letâ€™s test out a cat detector convnet already now)"
  },
  {
    "objectID": "slides/3-convolutions.html#decomposition-into-simple-patters-theory-vs-practice-1",
    "href": "slides/3-convolutions.html#decomposition-into-simple-patters-theory-vs-practice-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Decomposition into simple patters: Theory vs practice",
    "text": "Decomposition into simple patters: Theory vs practice\nOur test image:\n\n\n\n\n\n\nFrom F. Chollet: Deep Learning with Python"
  },
  {
    "objectID": "slides/3-convolutions.html#layer-activations",
    "href": "slides/3-convolutions.html#layer-activations",
    "title": "DAT255: Deep learning engineering",
    "section": "Layer activations",
    "text": "Layer activations\nWe can visualise what each filter does by looking at its activation on the test image: The output after the convolution and applying the activation function.\nExamples:\n\n\n\n\n\n\n\n\n\nLayer 1, filter 4\n\n\n\n\n\n\n\nLayer 1, filter 7"
  },
  {
    "objectID": "slides/3-convolutions.html#layer-activations-1",
    "href": "slides/3-convolutions.html#layer-activations-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Layer activations",
    "text": "Layer activations\nRepeat for all filters in all layers:\nLayer 1 and 2:"
  },
  {
    "objectID": "slides/3-convolutions.html#layer-activations-2",
    "href": "slides/3-convolutions.html#layer-activations-2",
    "title": "DAT255: Deep learning engineering",
    "section": "Layer activations",
    "text": "Layer activations\nRepeat for all filters in all layers:\nLayer 3:"
  },
  {
    "objectID": "slides/3-convolutions.html#layer-activations-3",
    "href": "slides/3-convolutions.html#layer-activations-3",
    "title": "DAT255: Deep learning engineering",
    "section": "Layer activations",
    "text": "Layer activations\nRepeat for all filters in all layers:\nLayer 4 (last):"
  },
  {
    "objectID": "slides/1-welcome.html#what-can-you-do-with-deep-learning",
    "href": "slides/1-welcome.html#what-can-you-do-with-deep-learning",
    "title": "DAT255: Deep learning",
    "section": "What can you do with deep learning?",
    "text": "What can you do with deep learning?"
  },
  {
    "objectID": "slides/1-welcome.html#stable-diffusion-dall-e",
    "href": "slides/1-welcome.html#stable-diffusion-dall-e",
    "title": "DAT255: Deep learning",
    "section": "Stable Diffusion / DALL-E",
    "text": "Stable Diffusion / DALL-E\n\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#sora-openai",
    "href": "slides/1-welcome.html#sora-openai",
    "title": "DAT255: Deep learning",
    "section": "Sora (OpenAI)",
    "text": "Sora (OpenAI)\n\n\nVideo\n\n\nVideo\n\n\nVideo\n\n\nVideo\n\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#segment-anything",
    "href": "slides/1-welcome.html#segment-anything",
    "title": "DAT255: Deep learning",
    "section": "Segment anything",
    "text": "Segment anything\n\nhttps://ai.meta.com/sam2/"
  },
  {
    "objectID": "slides/1-welcome.html#notebooklm",
    "href": "slides/1-welcome.html#notebooklm",
    "title": "DAT255: Deep learning",
    "section": "NotebookLM",
    "text": "NotebookLM\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#cursor",
    "href": "slides/1-welcome.html#cursor",
    "title": "DAT255: Deep learning",
    "section": "Cursor",
    "text": "Cursor\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#section-1",
    "href": "slides/1-welcome.html#section-1",
    "title": "DAT255: Deep learning",
    "section": "",
    "text": "Video\n\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#practical-things-in-dat255",
    "href": "slides/1-welcome.html#practical-things-in-dat255",
    "title": "DAT255: Deep learning",
    "section": "Practical things in DAT255",
    "text": "Practical things in DAT255"
  },
  {
    "objectID": "slides/1-welcome.html#textbook",
    "href": "slides/1-welcome.html#textbook",
    "title": "DAT255: Deep learning",
    "section": "Textbook",
    "text": "Textbook\nA. GÃ©ron: Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow (3rd edition)\n\n\nChapters:\n\n\n10 Intro to NNs\n11 Training deep neural networks\n12 Custom models and training with TensorFlow\n13 Loading and preprocessing data with TensorFlow\n14 Deep computer vision using CNNs\n15 Processing sequences using RNNs and CNNs\n16 Natural language processing with RNNs and attention\n17 Autoencoders, GANs and diffusion models\nNot 18\n19 Training and deploying TensorFlow models at scale"
  },
  {
    "objectID": "slides/1-welcome.html#extra-resources",
    "href": "slides/1-welcome.html#extra-resources",
    "title": "DAT255: Deep learning",
    "section": "Extra resources",
    "text": "Extra resources\n\nFramework documentation:\n\nThe Keras documentation and examples\nThe TensorFlow documentation and examples\n\nVarious research blogs\nOther reputable internet material\n\nYou are expected to research certain topics and find supporting material yourself (especially for the project work)"
  },
  {
    "objectID": "slides/1-welcome.html#interaction",
    "href": "slides/1-welcome.html#interaction",
    "title": "DAT255: Deep learning",
    "section": "Interaction",
    "text": "Interaction\n\n\n\nMuch of this course is based on gaining experience with deep learning by working on problems.\nOccationally we will ask YOU to share your experience by presenting your work in class.\n\nğŸ‘©â€ğŸ’»ğŸ¤“"
  },
  {
    "objectID": "slides/1-welcome.html#assessment",
    "href": "slides/1-welcome.html#assessment",
    "title": "DAT255: Deep learning",
    "section": "Assessment",
    "text": "Assessment\n\n\n\nThe exam has two parts:\n\nGroup project report, counts 50%\nShort written exam, counts 50%\n\nExam date will be posted on StudentWeb\nLast chance for registering for the exam is Feb.Â 2"
  },
  {
    "objectID": "slides/1-welcome.html#project-work",
    "href": "slides/1-welcome.html#project-work",
    "title": "DAT255: Deep learning",
    "section": "Project work",
    "text": "Project work\nThe project work puts the engineering into Deep learning engineering\nPrimary goal:  Build and deploy a deep learning-based application, based on the theory, techniques and tools you learn in this course\n\n\n\nSecondary goals:  Make something that is\n\nUseful\nFun\nUseful and fun"
  },
  {
    "objectID": "slides/1-welcome.html#project-work-1",
    "href": "slides/1-welcome.html#project-work-1",
    "title": "DAT255: Deep learning",
    "section": "Project work",
    "text": "Project work\nThe project work puts the engineering into Deep learning engineering\nPrimary goal:  Build and deploy a deep learning-based application, based on the theory, techniques and tools you learn in this course\nTopic options:\n\nChoose yourself\nChoose from a project catalog (will be published on canvas)\n\nAll projects, along with a plan and description, must be approved beforehand\nğŸ“† Submission deadline to be determined based on your input"
  },
  {
    "objectID": "slides/1-welcome.html#canvas",
    "href": "slides/1-welcome.html#canvas",
    "title": "DAT255: Deep learning",
    "section": "Canvas",
    "text": "Canvas\nThe canonical source of information is Canvas"
  },
  {
    "objectID": "slides/1-welcome.html#calendar",
    "href": "slides/1-welcome.html#calendar",
    "title": "DAT255: Deep learning",
    "section": "Calendar",
    "text": "Calendar"
  },
  {
    "objectID": "slides/1-welcome.html#deep-learning",
    "href": "slides/1-welcome.html#deep-learning",
    "title": "DAT255: Deep learning",
    "section": "Deep learning",
    "text": "Deep learning"
  },
  {
    "objectID": "slides/1-welcome.html#ai-vs-ml-vs-dl",
    "href": "slides/1-welcome.html#ai-vs-ml-vs-dl",
    "title": "DAT255: Deep learning",
    "section": "AI vs ML vs DL",
    "text": "AI vs ML vs DL\n\n\n\nWikiMedia Commons"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning",
    "title": "DAT255: Deep learning",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\n\n\n\n\nArtificial neural network McCulloch & Pitts, 1943\n\n\n\n\\[\n\\small\na = \\sum_{i=1}^{M} w_ix_i\n\\] \\[\n\\small\ny = f(a)\n\\]"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-1",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-1",
    "title": "DAT255: Deep learning",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\nThe perceptron Rosenblatt 1960\n\n\n\n\n\n\n\n\\[\n\\small\nf(a) =\n\\begin{cases}\n0, & a \\leq 0 \\\\\n1, & a &gt; 0\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-2",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-2",
    "title": "DAT255: Deep learning",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\nBackpropagation Rumelhart, Hinton & Williams, 1986\n\n\nALVINN, 1989\n\n\n\n\n\n\n\nLeNet, 1989"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-3",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-3",
    "title": "DAT255: Deep learning",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\n\n\nAlexNet, 2012"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-4",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-4",
    "title": "DAT255: Deep learning",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\n\n\nLarge language models (LLMs), 2017\nGhatGPT 2022"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-5",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-5",
    "title": "DAT255: Deep learning",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\n\n\nDiffusion models, 2020\n\n\n\nTF playground"
  },
  {
    "objectID": "slides/1-welcome.html#section-9",
    "href": "slides/1-welcome.html#section-9",
    "title": "DAT255: Deep learning",
    "section": "",
    "text": "Maslej et al.Â (2024) Artificial intelligence index report 2024. arXiv:2405.19522"
  },
  {
    "objectID": "slides/1-welcome.html#section-10",
    "href": "slides/1-welcome.html#section-10",
    "title": "DAT255: Deep learning",
    "section": "",
    "text": "TensorFlowplayground"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DAT255 lecture notes",
    "section": "",
    "text": "Published after each lecture week â€“ see Canvas for additional material.\nMonday week 3: Welcome and introduction\nThursday week 3: The tools of deep learning\nMonday week 4: Computer vision and the concepts of layers"
  },
  {
    "objectID": "slides/2-tools.html#frameworks",
    "href": "slides/2-tools.html#frameworks",
    "title": "DAT255: Deep learning engineering",
    "section": "Frameworks",
    "text": "Frameworks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHigh-level\n\n\nCompute\n\n\nSupporting"
  },
  {
    "objectID": "slides/2-tools.html#frameworks-1",
    "href": "slides/2-tools.html#frameworks-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Frameworks",
    "text": "Frameworks\npython is the de-facto language for deep learning\nIn case you need a refresher, look at e.g.\n\nKaggle Learn: https://www.kaggle.com/learn/python\nGoogle Edu: https://developers.google.com/edu/python\n\n\nTechnically, we use python as a configuration language while the framework backends are C++/CUDA (but we wonâ€™t touch this)\nFor deployment, there are hooks to Haskell / C# / Julia / Java / R / Ruby / Rust / Scala / Perl and others\nWe assume you have been exposed to NumPy â€“ although itâ€™s no requirement"
  },
  {
    "objectID": "slides/2-tools.html#this-week",
    "href": "slides/2-tools.html#this-week",
    "title": "DAT255: Deep learning engineering",
    "section": "This week",
    "text": "This week\n\n\n\n\n\n\n\nEnvironment setup: Check our GitHub\nIntro to TensorFlow:We look at this today"
  },
  {
    "objectID": "slides/2-tools.html#computing-resources",
    "href": "slides/2-tools.html#computing-resources",
    "title": "DAT255: Deep learning engineering",
    "section": "Computing resources",
    "text": "Computing resources\nMany exercises in this course are compute intensive, and will benefit from a hardware accelerator (i.e.Â a GPU)\nSome options:\n\nYour own computer (NVIDIA GPU or M-series Mac)\nCloud services\n\nGoogle Colab: T4 for free\nKaggle Notebooks: P100 for free\n(and others)\n\nResearch group hardware If you are connected to some research group at HVL/UiB"
  },
  {
    "objectID": "slides/2-tools.html#low-level-tensorflow",
    "href": "slides/2-tools.html#low-level-tensorflow",
    "title": "DAT255: Deep learning engineering",
    "section": "Low-level TensorFlow",
    "text": "Low-level TensorFlow\nMost things work like NumPy, but with the benefit of GPU support and JIT compilation.\nThe core object is the Tensor, which is basically a multidimensional array.\n\nNumPy\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.array([[1,2,3], [4,5,6]], dtype=np.float32)\n&gt;&gt;&gt; print(x)\n[[1. 2. 3.]\n [4. 5. 6.]]\n\n\nTensorFlow\n&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; x = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)\n&gt;&gt;&gt; print(x)\ntf.Tensor(\n[[1. 2. 3.]\n [4. 5. 6.]], shape=(2, 3), dtype=float32)"
  },
  {
    "objectID": "slides/2-tools.html#low-level-tensorflow-the-tensor",
    "href": "slides/2-tools.html#low-level-tensorflow-the-tensor",
    "title": "DAT255: Deep learning engineering",
    "section": "Low-level TensorFlow: The Tensor",
    "text": "Low-level TensorFlow: The Tensor\nTensors are immutable, and are useful for storing constant values such as input data\nFor values that will be updated (such as model weights), use a Variable:\n&gt;&gt;&gt; y = tf.Variable([[1,2,3], [4,5,6]], dtype=tf.float32, name=\"My first variable\")\n&gt;&gt;&gt; y[0,1].assign(50)\n&lt;tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\narray([[ 1., 50.,  3.],\n       [ 4.,  5.,  6.]], dtype=float32)&gt;"
  },
  {
    "objectID": "slides/2-tools.html#low-level-tensorflow-simple-operations",
    "href": "slides/2-tools.html#low-level-tensorflow-simple-operations",
    "title": "DAT255: Deep learning engineering",
    "section": "Low-level TensorFlow: Simple operations",
    "text": "Low-level TensorFlow: Simple operations\nBasic math is accessed through operators\n&gt;&gt;&gt; a = b + c       # Element-wise addition\n&gt;&gt;&gt; a = b * c       # Element-wise multiplication (Hadamard product)\n&gt;&gt;&gt; a = b @ c       # Matrix multiplication\nwhile more complicated stuff is available as functions in tf.math\n\nNotice in particular the reduce_ functions, which look different from NumPy:\n&gt;&gt;&gt; x = tf.constant([[1,2,3], [4,5,6]]); print(x)\ntf.Tensor(\n[[1 2 3]\n [4 5 6]], shape=(2, 3), dtype=int32)\n\n&gt;&gt;&gt; tf.math.reduce_sum(x, axis=0)\n&lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 9], dtype=int32)&gt;\n\n&gt;&gt;&gt; tf.math.reduce_sum(x, axis=1)\n&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 6, 15], dtype=int32)&gt;\n\n&gt;&gt;&gt; tf.math.reduce_sum(x, axis=None)\n&lt;tf.Tensor: shape=(), dtype=int32, numpy=21&gt;"
  },
  {
    "objectID": "slides/2-tools.html#low-level-tensorflow-shapes",
    "href": "slides/2-tools.html#low-level-tensorflow-shapes",
    "title": "DAT255: Deep learning engineering",
    "section": "Low-level TensorFlow: Shapes",
    "text": "Low-level TensorFlow: Shapes\nBroadcasting works like in NumPy:\n&gt;&gt;&gt; x = tf.constant([1,2,3], dtype=tf.float32)\n&gt;&gt;&gt; x + 1\n&lt;tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 3., 4.], dtype=float32)&gt;\nSame for shapes:"
  },
  {
    "objectID": "slides/2-tools.html#a-typical-shape-128-299-299-3",
    "href": "slides/2-tools.html#a-typical-shape-128-299-299-3",
    "title": "DAT255: Deep learning engineering",
    "section": "A typical shape: [128, 299, 299, 3]",
    "text": "A typical shape: [128, 299, 299, 3]\nImages are typically represented as [height, width, channel]\n\n\n\n\n\n\nDuring model training we want to do minibatch gradient descent, and load a subset of the data at a time\n This adds a fourth batch dimension: [batch, height, width, channel]\nWhen processing single data points, we often need to add or remove it:\nimg = tf.expand_dims(img, 0)    # [24, 24, 3]    -&gt; [1, 24, 24, 3]\nimg = tf.squeeze(img)           # [1, 24, 24, 3] -&gt; [24, 24, 3]"
  },
  {
    "objectID": "slides/2-tools.html#run-computations-on-a-gpu",
    "href": "slides/2-tools.html#run-computations-on-a-gpu",
    "title": "DAT255: Deep learning engineering",
    "section": "Run computations on a GPU",
    "text": "Run computations on a GPU\nTensorFlow will automatically try to use the fastest compute device available\nTensor operations are typically faster when parallelised on a GPU\n\n\n\nWhile this is automatic, it can also be forced:\nwith tf.device('CPU:0'):\n  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n  b = tf.Variable([[1.0, 2.0, 3.0]])\n\nwith tf.device('GPU:0'):\n  k = a * b\n\nprint(k)"
  },
  {
    "objectID": "slides/2-tools.html#automatic-differentiation",
    "href": "slides/2-tools.html#automatic-differentiation",
    "title": "DAT255: Deep learning engineering",
    "section": "Automatic differentiation",
    "text": "Automatic differentiation\nLetâ€™s try to compute this derivative:\n\\[\n\\small\n\\frac{\\mathrm{d}}{\\mathrm{d}x} \\Big|_{x=1} \\; x^2 + 2x - 5\n\\]\n\n\\[\n\\small\n= 2x + 2 \\big|_{x=1} = 2 \\cdot 1 + 2 = 4\n\\]\n\n\nTurns out TensorFlow can do it for us:\ndef f(x):\n  return x**2 + 2*x - 5\n\nx = tf.Variable(1.0)\n\nwith tf.GradientTape() as tape:\n  y = f(x)\n\nd_dx = tape.gradient(y, x)\nprint(d_dx)\n\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=4.0&gt;"
  },
  {
    "objectID": "slides/2-tools.html#keras",
    "href": "slides/2-tools.html#keras",
    "title": "DAT255: Deep learning engineering",
    "section": "Keras",
    "text": "Keras\nThe Keras framework contains all the high-level components we need to construct and train a neural network:\n\nkeras.layers: Different types of layers and activation functions\nkeras.callbacks: Monitor, modify or stop the training process\nkeras.optimizers: Optimisation algorithms\nkeras.metrics: Performance metrics\nkeras.losses: Loss functions\nkeras.datasets: Small datasets for testing\nkeras.applications: Pre-trained networks for different tasks"
  },
  {
    "objectID": "slides/2-tools.html#referansegruppe",
    "href": "slides/2-tools.html#referansegruppe",
    "title": "DAT255: Deep learning engineering",
    "section": "Referansegruppe",
    "text": "Referansegruppe"
  }
]