[
  {
    "objectID": "slides/4-training.html#the-parameters-of-a-neural-network",
    "href": "slides/4-training.html#the-parameters-of-a-neural-network",
    "title": "DAT255: Deep learning engineering",
    "section": "The parameters of a neural network",
    "text": "The parameters of a neural network\nRecall the simple formulation of a machine learning model:\n\n\\[\n\\large \\hat{\\color{DarkBlue}{y}} = \\color{Purple}{f}(\\color{DarkOrange}{\\mathbf{x}}, \\boldsymbol{\\color{teal}{\\theta}})\n\\]\n\nwhere\n\n\\(\\hat{\\color{DarkBlue}{y}}\\) is the prediction\n\\(\\color{DarkOrange}{\\mathbf{x}}\\)¬†is a data point\n\\(\\boldsymbol{\\color{teal}{\\theta}}\\) are parameters of the model"
  },
  {
    "objectID": "slides/4-training.html#the-parameters-of-a-neural-network-1",
    "href": "slides/4-training.html#the-parameters-of-a-neural-network-1",
    "title": "DAT255: Deep learning engineering",
    "section": "The parameters of a neural network",
    "text": "The parameters of a neural network\n\n\n\n\n\nThe parameters of the simple fully-connected network are\n\none weight per connection (line)\none bias term per node (circle)\n\n(for other types of layers, there are other types of parameters)"
  },
  {
    "objectID": "slides/4-training.html#the-parameters-of-a-neural-network-2",
    "href": "slides/4-training.html#the-parameters-of-a-neural-network-2",
    "title": "DAT255: Deep learning engineering",
    "section": "The parameters of a neural network",
    "text": "The parameters of a neural network"
  },
  {
    "objectID": "slides/4-training.html#the-activation-function",
    "href": "slides/4-training.html#the-activation-function",
    "title": "DAT255: Deep learning engineering",
    "section": "The activation function",
    "text": "The activation function\nWhat separates a neural network from standard linear regression is the non-linear activation function.\n\n(And not that we have many layers ‚Äì stacking linear functions is still a linear function)\n\\[\n\\small\n\\begin{aligned}\n\\color{DarkBlue}{f}(x) &= 2x + 3  & (\\mathrm{linear}) \\\\\n\\color{Purple}{g}(x) &= 5x -1 & (\\mathrm{linear}) \\\\\n\\color{DarkBlue}{f}(\\color{Purple}{g}(x)) &= 2(5x-1) +3 &  \\\\\n&= 10x + 1 & (\\mathrm{also\\;linear})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/4-training.html#activation-function",
    "href": "slides/4-training.html#activation-function",
    "title": "DAT255: Deep learning engineering",
    "section": "Activation function",
    "text": "Activation function\n\n\nA good activation function is\n\nNonlinear\nDifferentiable*\nSwitches from off for negative inputs to on for positive inputs\n\n\n\n\n\n\nSigmoid\n\n\n\n\n\ntanh\n\n\n\n\n\nReLU\n\n\n\n\n\nGELU\n\n\n\n\n\nSwish\n\n\n\n\n\n\n\n\n*At least piecewise differentiable"
  },
  {
    "objectID": "slides/4-training.html#last-layer-activation-functions",
    "href": "slides/4-training.html#last-layer-activation-functions",
    "title": "DAT255: Deep learning engineering",
    "section": "Last layer activation functions",
    "text": "Last layer activation functions\nIn the final layer of the network, we need to choose an activation function that suits our task\n\n\nRegression:\nNo activation ‚Äì just sum the weighted connections. Output range \\((-\\infty, \\infty)\\) Also called linear activation.  keras.layers.Dense(units, activation=None)\nClassification:\nNeed something with output range \\([0, 1]\\)\n\nBinary classification: Use sigmoid keras.layers.Dense(1, activation='sigmoid)\nMulticlass: Use softmax keras.layers.Dense(10, activation='softmax') (remember one-hot encoding)"
  },
  {
    "objectID": "slides/4-training.html#finding-optimal-parameters",
    "href": "slides/4-training.html#finding-optimal-parameters",
    "title": "DAT255: Deep learning engineering",
    "section": "Finding optimal parameters",
    "text": "Finding optimal parameters\n\n\n\n\n\nFor large networks we get a huge number of parameters\nNeed a clever way to optimise all at the same time.\n\nThe solution is backpropagation, which is relies on the network output being differentiable with respect to its parameters."
  },
  {
    "objectID": "slides/4-training.html#backpropagation",
    "href": "slides/4-training.html#backpropagation",
    "title": "DAT255: Deep learning engineering",
    "section": "Backpropagation",
    "text": "Backpropagation\nStep 1:\n\n\n\n\n\n\n\n\n\n\n\nRandomly initialise parameters\n\n\n\nRun a forward pass on a mini-batch, i.e.¬†compute predictions, but keep track of the output for each node"
  },
  {
    "objectID": "slides/4-training.html#backpropagation-1",
    "href": "slides/4-training.html#backpropagation-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Backpropagation",
    "text": "Backpropagation\nStep 2:\n\n\n\n\n\n\n\\[\n\\mathrm{loss}(\\hat{y}, y)\n\\]\n\n\nCompute the loss, which measures how big the error is"
  },
  {
    "objectID": "slides/4-training.html#backpropagation-2",
    "href": "slides/4-training.html#backpropagation-2",
    "title": "DAT255: Deep learning engineering",
    "section": "Backpropagation",
    "text": "Backpropagation\nStep 3:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompute how much each parameter contributed to the loss (i.e.¬†compute the gradient for each parameter)\n\nStart at the last layer and move backwards (backwards pass)"
  },
  {
    "objectID": "slides/4-training.html#backpropagation-3",
    "href": "slides/4-training.html#backpropagation-3",
    "title": "DAT255: Deep learning engineering",
    "section": "Backpropagation",
    "text": "Backpropagation\nStep 4:\n\n\n\n\n\n\nRun one step of gradient descent to find better values for all parameters"
  },
  {
    "objectID": "slides/4-training.html#gradient-descent",
    "href": "slides/4-training.html#gradient-descent",
    "title": "DAT255: Deep learning engineering",
    "section": "Gradient descent",
    "text": "Gradient descent\n\n\n\n\n\n\n\nThe gradient points towards direction of maximum increase of the loss function.\nWe want to find the minimum, so need the negative gradient.\n\\[\n\\nabla \\color{MediumVioletRed}{L}(\\color{teal}{\\boldsymbol{\\theta}}) =\n\\begin{bmatrix}\n  \\frac{\\partial \\color{MediumVioletRed}{L}}{\\partial \\color{teal}{\\theta}_0} \\\\\n  \\vdots \\\\\n  \\frac{\\partial \\color{MediumVioletRed}{L}}{\\partial \\color{teal}{\\theta}_n} \\\\\n\\end{bmatrix}\n\\]\n\n\n Vector in parameterspace\n\n\n Gradient"
  },
  {
    "objectID": "slides/4-training.html#gradient-descent-1",
    "href": "slides/4-training.html#gradient-descent-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Gradient descent",
    "text": "Gradient descent\n\n\n\n\n\n\n\nWith the gradient in place, we take steps downward (along the negative gradient), towards the optimal solution:\n\\[\n\\small\n\\boldsymbol{\\color{teal}{\\theta}}^{n+1} = \\boldsymbol{\\color{teal}{\\theta}}^n - \\eta \\nabla \\color{Purple}{L}\n\\]\nHere \\(\\eta\\)¬†is the learning rate"
  },
  {
    "objectID": "slides/4-training.html#learning-rate",
    "href": "slides/4-training.html#learning-rate",
    "title": "DAT255: Deep learning engineering",
    "section": "Learning rate",
    "text": "Learning rate\n\n\n\nLearning rate is a hyperparameter\n\n\n\n\n\n\n\n\n\nTo small (slow convergence)\n\n\n\n\n\n\n\nJust right\n\n\n\n\n\n\n\nTo high (no convergence)"
  },
  {
    "objectID": "slides/4-training.html#practical-problems",
    "href": "slides/4-training.html#practical-problems",
    "title": "DAT255: Deep learning engineering",
    "section": "Practical problems",
    "text": "Practical problems"
  },
  {
    "objectID": "slides/4-training.html#practical-problems-1",
    "href": "slides/4-training.html#practical-problems-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Practical problems",
    "text": "Practical problems\n\n\nLocalminimum -&gt; bad predictions"
  },
  {
    "objectID": "slides/4-training.html#practical-problems-2",
    "href": "slides/4-training.html#practical-problems-2",
    "title": "DAT255: Deep learning engineering",
    "section": "Practical problems",
    "text": "Practical problems\n\n\nLocalminimum -&gt; bad predictions\n\n\nPlateau -&gt; slow convergence\n\n\nWill try to solve theseproblems on Thursday"
  },
  {
    "objectID": "slides/4-training.html#vanishing-and-exploding-gradients",
    "href": "slides/4-training.html#vanishing-and-exploding-gradients",
    "title": "DAT255: Deep learning engineering",
    "section": "Vanishing and exploding gradients",
    "text": "Vanishing and exploding gradients\nWhen backpropagation steps through the network layers, we can get unfortunate amplification effects:\n\nVanishing gradients: ¬†¬† Gradients go towards zero  no learning\nExploding gradients: ¬†¬† Gradients go towards infinity  no learning\n\n\nGet improved training stability if we can make the variance of the output of a layer to be similar to the variance or the input:"
  },
  {
    "objectID": "slides/4-training.html#some-tricks",
    "href": "slides/4-training.html#some-tricks",
    "title": "DAT255: Deep learning engineering",
    "section": "Some tricks",
    "text": "Some tricks\n\n\nCommon apporaches to avoid vanishing/exploding gradients:\n\nChoose a non-saturating activation function (like ReLU)\n\n\n\nInitialise each layer‚Äôs parameters according to number of input and output connections\n\n\n\n\n\nInitialisation method\nActivation function\n\n\n\n\nGlorot\nNone, tanh, sigmoid, softmax\n\n\nHe (Kaiming)\nReLU, GELU, Swish, ‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSigmoid\n\n\n\n\n\n\n\n\n\nReLU"
  },
  {
    "objectID": "slides/4-training.html#some-tricks-1",
    "href": "slides/4-training.html#some-tricks-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Some tricks",
    "text": "Some tricks\n\n\nCommon apporaches to avoid vanishing/exploding gradients:\n\nChoose a non-saturating activation function (like ReLU)\n\n\n\n\n\nInitialise each layer‚Äôs parameters according to number of input and output connections\n\n\n\n\n\nInitialisation method\nActivation function\n\n\n\n\nGlorot\nNone, tanh, sigmoid, softmax\n\n\nHe (Kaiming)\nReLU, GELU, Swish, ‚Ä¶\n\n\n\n\n\nkeras.layers.Dense(\n    units,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    lora_rank=None,\n    **kwargs\n)"
  },
  {
    "objectID": "slides/4-training.html#some-tricks-2",
    "href": "slides/4-training.html#some-tricks-2",
    "title": "DAT255: Deep learning engineering",
    "section": "Some tricks",
    "text": "Some tricks\n\n\nCommon apporaches to avoid vanishing/exploding gradients:\n\nChoose a non-saturating activation function (like ReLU)\n\n\n\n\n\nInitialise each layer‚Äôs parameters according to number of input and output connections\n\n\n\n\n\nAdd normalisation layers to the model"
  },
  {
    "objectID": "slides/4-training.html#normalisation-layers",
    "href": "slides/4-training.html#normalisation-layers",
    "title": "DAT255: Deep learning engineering",
    "section": "Normalisation layers",
    "text": "Normalisation layers\n\n\nMost common: keras.layers.BatchNormalisation\n\nFrom the documentation: (read the textbook for further details)\n\nBatch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.\nImportantly, batch normalization works differently during training and during inference.\n\n\n\n\n\n\nkeras.layers.BatchNormalization(\n    axis=-1,\n    momentum=0.99,\n    epsilon=0.001,\n    center=True,\n    scale=True,\n    beta_initializer=\"zeros\",\n    gamma_initializer=\"ones\",\n    moving_mean_initializer=\"zeros\",\n    moving_variance_initializer=\"ones\",\n    beta_regularizer=None,\n    gamma_regularizer=None,\n    beta_constraint=None,\n    gamma_constraint=None,\n    synchronized=False,\n    **kwargs\n)\n\n Comes with sensible defaults"
  },
  {
    "objectID": "slides/4-training.html#regularisation",
    "href": "slides/4-training.html#regularisation",
    "title": "DAT255: Deep learning engineering",
    "section": "Regularisation",
    "text": "Regularisation\nThe usual L1 and L2 regularisation can be applied to neural network nodes\nTechnically three different options for where to add it (see docs):\nlayer = keras.layers.Dense(\n    units=64, \n    kernel_regularizer=keras.regularizers.L1L2(l1=1e-5, l2=1e-4),\n    bias_regularizer=keras.regularizers.L2(1e-4),\n    activity_regularizer=keras.regularizers.L1(1e-5)\n)"
  },
  {
    "objectID": "slides/4-training.html#dropout-regularisation",
    "href": "slides/4-training.html#dropout-regularisation",
    "title": "DAT255: Deep learning engineering",
    "section": "Dropout regularisation",
    "text": "Dropout regularisation\nOne of the most common regularisation techniques is very simple:\nAt each training step, randomly remove a fraction of the neurons\n\n\n\n\n\nPrevents neuron co-adaptation\n(should be enabled during training time only)"
  },
  {
    "objectID": "slides/4-training.html#dropout-regularisation-1",
    "href": "slides/4-training.html#dropout-regularisation-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Dropout regularisation",
    "text": "Dropout regularisation\nThe rate adjusts the percentage of nodes dropped\n\n\n\nkeras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)\n\n\n\nAfter convolutional layers it is recommended to rather use spatial dropout, which drops entire feature maps\n\n\n\nkeras.layers.SpatialDropout2D(\n    rate, data_format=None, seed=None, name=None, dtype=None\n)"
  },
  {
    "objectID": "slides/4-training.html#putting-together-an-improved-network",
    "href": "slides/4-training.html#putting-together-an-improved-network",
    "title": "DAT255: Deep learning engineering",
    "section": "Putting together an improved network",
    "text": "Putting together an improved network\nfrom keras.layers import (\n  Input, Rescaling, Conv2D, BatchNormalization,\n  MaxPooling2D, Activation, Dropout, Dense\n)\n\nmodel = keras.Sequential([\n  keras.Input(shape=(128, 128, 3)),\n  Rescaling(1.0 / 255),\n  Conv2D(128, kernel_size=3, kernel_initializer=\"he_uniform\", padding=\"same\"),\n  BatchNormalization(),\n  Activation(\"relu\"),\n  MaxPooling2D(3, padding=\"same\"),\n  # ...\n  # (more layers)\n  # ...\n  Conv2D(128, kernel_size=3, kernel_initializer=\"he_uniform\", padding=\"same\"),\n  BatchNormalization(),\n  layers.Activation(\"relu\"),\n  MaxPooling2D(3, padding=\"same\"),\n  Flatten(),\n  Dropout(0.3),\n  Dense(num_classes, activation=\"softmax\"),\n])"
  },
  {
    "objectID": "slides/4-training.html#best-practices",
    "href": "slides/4-training.html#best-practices",
    "title": "DAT255: Deep learning engineering",
    "section": "Best practices",
    "text": "Best practices\nWith the choice of\n\nArchitecture (layers and nodes)\nParameter initialisers\nActivation functions\nRegularisation\nOptimisation algorithm\nLearning rate and scheduling\n\nthe search space for finding the optimal solution is huge\nGuidelines from this and next week are meant to save time, but are not absolute.\n(Better guidelines will come along the next few years anyway)"
  },
  {
    "objectID": "slides/4-training.html#ai-assistant",
    "href": "slides/4-training.html#ai-assistant",
    "title": "DAT255: Deep learning engineering",
    "section": "AI Assistant",
    "text": "AI Assistant"
  },
  {
    "objectID": "slides/2-tools.html#frameworks",
    "href": "slides/2-tools.html#frameworks",
    "title": "DAT255: Deep learning engineering",
    "section": "Frameworks",
    "text": "Frameworks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHigh-level\n\n\nCompute\n\n\nSupporting"
  },
  {
    "objectID": "slides/2-tools.html#frameworks-1",
    "href": "slides/2-tools.html#frameworks-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Frameworks",
    "text": "Frameworks\npython is the de-facto language for deep learning\nIn case you need a refresher, look at e.g.\n\nKaggle Learn: https://www.kaggle.com/learn/python\nGoogle Edu: https://developers.google.com/edu/python\n\n\nTechnically, we use python as a configuration language while the framework backends are C++/CUDA (but we won‚Äôt touch this)\nFor deployment, there are hooks to Haskell / C# / Julia / Java / R / Ruby / Rust / Scala / Perl and others\nWe assume you have been exposed to NumPy ‚Äì although it‚Äôs no requirement"
  },
  {
    "objectID": "slides/2-tools.html#this-week",
    "href": "slides/2-tools.html#this-week",
    "title": "DAT255: Deep learning engineering",
    "section": "This week",
    "text": "This week\n\n\n\n\n\n\n\nEnvironment setup: Check our GitHub\nIntro to TensorFlow:We look at this today"
  },
  {
    "objectID": "slides/2-tools.html#computing-resources",
    "href": "slides/2-tools.html#computing-resources",
    "title": "DAT255: Deep learning engineering",
    "section": "Computing resources",
    "text": "Computing resources\nMany exercises in this course are compute intensive, and will benefit from a hardware accelerator (i.e.¬†a GPU)\nSome options:\n\nYour own computer (NVIDIA GPU or M-series Mac)\nCloud services\n\nGoogle Colab: T4 for free\nKaggle Notebooks: P100 for free\n(and others)\n\nResearch group hardware If you are connected to some research group at HVL/UiB"
  },
  {
    "objectID": "slides/2-tools.html#low-level-tensorflow",
    "href": "slides/2-tools.html#low-level-tensorflow",
    "title": "DAT255: Deep learning engineering",
    "section": "Low-level TensorFlow",
    "text": "Low-level TensorFlow\nMost things work like NumPy, but with the benefit of GPU support and JIT compilation.\nThe core object is the Tensor, which is basically a multidimensional array.\n\nNumPy\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x = np.array([[1,2,3], [4,5,6]], dtype=np.float32)\n&gt;&gt;&gt; print(x)\n[[1. 2. 3.]\n [4. 5. 6.]]\n\n\nTensorFlow\n&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; x = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)\n&gt;&gt;&gt; print(x)\ntf.Tensor(\n[[1. 2. 3.]\n [4. 5. 6.]], shape=(2, 3), dtype=float32)"
  },
  {
    "objectID": "slides/2-tools.html#low-level-tensorflow-the-tensor",
    "href": "slides/2-tools.html#low-level-tensorflow-the-tensor",
    "title": "DAT255: Deep learning engineering",
    "section": "Low-level TensorFlow: The Tensor",
    "text": "Low-level TensorFlow: The Tensor\nTensors are immutable, and are useful for storing constant values such as input data\nFor values that will be updated (such as model weights), use a Variable:\n&gt;&gt;&gt; y = tf.Variable([[1,2,3], [4,5,6]], dtype=tf.float32, name=\"My first variable\")\n&gt;&gt;&gt; y[0,1].assign(50)\n&lt;tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\narray([[ 1., 50.,  3.],\n       [ 4.,  5.,  6.]], dtype=float32)&gt;"
  },
  {
    "objectID": "slides/2-tools.html#low-level-tensorflow-simple-operations",
    "href": "slides/2-tools.html#low-level-tensorflow-simple-operations",
    "title": "DAT255: Deep learning engineering",
    "section": "Low-level TensorFlow: Simple operations",
    "text": "Low-level TensorFlow: Simple operations\nBasic math is accessed through operators\n&gt;&gt;&gt; a = b + c       # Element-wise addition\n&gt;&gt;&gt; a = b * c       # Element-wise multiplication (Hadamard product)\n&gt;&gt;&gt; a = b @ c       # Matrix multiplication\nwhile more complicated stuff is available as functions in tf.math\n\nNotice in particular the reduce_ functions, which look different from NumPy:\n&gt;&gt;&gt; x = tf.constant([[1,2,3], [4,5,6]]); print(x)\ntf.Tensor(\n[[1 2 3]\n [4 5 6]], shape=(2, 3), dtype=int32)\n\n&gt;&gt;&gt; tf.math.reduce_sum(x, axis=0)\n&lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 9], dtype=int32)&gt;\n\n&gt;&gt;&gt; tf.math.reduce_sum(x, axis=1)\n&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 6, 15], dtype=int32)&gt;\n\n&gt;&gt;&gt; tf.math.reduce_sum(x, axis=None)\n&lt;tf.Tensor: shape=(), dtype=int32, numpy=21&gt;"
  },
  {
    "objectID": "slides/2-tools.html#low-level-tensorflow-shapes",
    "href": "slides/2-tools.html#low-level-tensorflow-shapes",
    "title": "DAT255: Deep learning engineering",
    "section": "Low-level TensorFlow: Shapes",
    "text": "Low-level TensorFlow: Shapes\nBroadcasting works like in NumPy:\n&gt;&gt;&gt; x = tf.constant([1,2,3], dtype=tf.float32)\n&gt;&gt;&gt; x + 1\n&lt;tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 3., 4.], dtype=float32)&gt;\nSame for shapes:"
  },
  {
    "objectID": "slides/2-tools.html#a-typical-shape-128-299-299-3",
    "href": "slides/2-tools.html#a-typical-shape-128-299-299-3",
    "title": "DAT255: Deep learning engineering",
    "section": "A typical shape: [128, 299, 299, 3]",
    "text": "A typical shape: [128, 299, 299, 3]\nImages are typically represented as [height, width, channel]\n\n\n\n\n\n\nDuring model training we want to do minibatch gradient descent, and load a subset of the data at a time\n This adds a fourth batch dimension: [batch, height, width, channel]\nWhen processing single data points, we often need to add or remove it:\nimg = tf.expand_dims(img, 0)    # [24, 24, 3]    -&gt; [1, 24, 24, 3]\nimg = tf.squeeze(img)           # [1, 24, 24, 3] -&gt; [24, 24, 3]"
  },
  {
    "objectID": "slides/2-tools.html#run-computations-on-a-gpu",
    "href": "slides/2-tools.html#run-computations-on-a-gpu",
    "title": "DAT255: Deep learning engineering",
    "section": "Run computations on a GPU",
    "text": "Run computations on a GPU\nTensorFlow will automatically try to use the fastest compute device available\nTensor operations are typically faster when parallelised on a GPU\n\n\n\nWhile this is automatic, it can also be forced:\nwith tf.device('CPU:0'):\n  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n  b = tf.Variable([[1.0, 2.0, 3.0]])\n\nwith tf.device('GPU:0'):\n  k = a * b\n\nprint(k)"
  },
  {
    "objectID": "slides/2-tools.html#automatic-differentiation",
    "href": "slides/2-tools.html#automatic-differentiation",
    "title": "DAT255: Deep learning engineering",
    "section": "Automatic differentiation",
    "text": "Automatic differentiation\nLet‚Äôs try to compute this derivative:\n\\[\n\\small\n\\frac{\\mathrm{d}}{\\mathrm{d}x} \\Big|_{x=1} \\; x^2 + 2x - 5\n\\]\n\n\\[\n\\small\n= 2x + 2 \\big|_{x=1} = 2 \\cdot 1 + 2 = 4\n\\]\n\n\nTurns out TensorFlow can do it for us:\ndef f(x):\n  return x**2 + 2*x - 5\n\nx = tf.Variable(1.0)\n\nwith tf.GradientTape() as tape:\n  y = f(x)\n\nd_dx = tape.gradient(y, x)\nprint(d_dx)\n\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=4.0&gt;"
  },
  {
    "objectID": "slides/2-tools.html#keras",
    "href": "slides/2-tools.html#keras",
    "title": "DAT255: Deep learning engineering",
    "section": "Keras",
    "text": "Keras\nThe Keras framework contains all the high-level components we need to construct and train a neural network:\n\nkeras.layers: Different types of layers and activation functions\nkeras.callbacks: Monitor, modify or stop the training process\nkeras.optimizers: Optimisation algorithms\nkeras.metrics: Performance metrics\nkeras.losses: Loss functions\nkeras.datasets: Small datasets for testing\nkeras.applications: Pre-trained networks for different tasks"
  },
  {
    "objectID": "slides/2-tools.html#referansegruppe",
    "href": "slides/2-tools.html#referansegruppe",
    "title": "DAT255: Deep learning engineering",
    "section": "Referansegruppe",
    "text": "Referansegruppe"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DAT255 lecture notes",
    "section": "",
    "text": "Published after each lecture week ‚Äì see Canvas for additional material.\nMonday week 3: Welcome and introduction\nThursday week 3: The tools of deep learning\nMonday week 4: Computer vision and the concepts of layers\nMonday week 5: Training deep neural networks"
  },
  {
    "objectID": "slides/1-welcome.html#what-can-you-do-with-deep-learning",
    "href": "slides/1-welcome.html#what-can-you-do-with-deep-learning",
    "title": "DAT255: Deep learning engineering",
    "section": "What can you do with deep learning?",
    "text": "What can you do with deep learning?"
  },
  {
    "objectID": "slides/1-welcome.html#stable-diffusion-dall-e",
    "href": "slides/1-welcome.html#stable-diffusion-dall-e",
    "title": "DAT255: Deep learning engineering",
    "section": "Stable Diffusion / DALL-E",
    "text": "Stable Diffusion / DALL-E\n\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#sora-openai",
    "href": "slides/1-welcome.html#sora-openai",
    "title": "DAT255: Deep learning engineering",
    "section": "Sora (OpenAI)",
    "text": "Sora (OpenAI)\n\n\nVideo\n\n\nVideo\n\n\nVideo\n\n\nVideo\n\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#segment-anything",
    "href": "slides/1-welcome.html#segment-anything",
    "title": "DAT255: Deep learning engineering",
    "section": "Segment anything",
    "text": "Segment anything\n\nhttps://ai.meta.com/sam2/"
  },
  {
    "objectID": "slides/1-welcome.html#notebooklm",
    "href": "slides/1-welcome.html#notebooklm",
    "title": "DAT255: Deep learning engineering",
    "section": "NotebookLM",
    "text": "NotebookLM\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#cursor",
    "href": "slides/1-welcome.html#cursor",
    "title": "DAT255: Deep learning engineering",
    "section": "Cursor",
    "text": "Cursor\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#section-1",
    "href": "slides/1-welcome.html#section-1",
    "title": "DAT255: Deep learning engineering",
    "section": "",
    "text": "Video\n\n\nVideo"
  },
  {
    "objectID": "slides/1-welcome.html#practical-things-in-dat255",
    "href": "slides/1-welcome.html#practical-things-in-dat255",
    "title": "DAT255: Deep learning engineering",
    "section": "Practical things in DAT255",
    "text": "Practical things in DAT255"
  },
  {
    "objectID": "slides/1-welcome.html#textbook",
    "href": "slides/1-welcome.html#textbook",
    "title": "DAT255: Deep learning engineering",
    "section": "Textbook",
    "text": "Textbook\nA. G√©ron: Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow (3rd edition)\n\n\nChapters:\n\n\n10 Intro to NNs\n11 Training deep neural networks\n12 Custom models and training with TensorFlow\n13 Loading and preprocessing data with TensorFlow\n14 Deep computer vision using CNNs\n15 Processing sequences using RNNs and CNNs\n16 Natural language processing with RNNs and attention\n17 Autoencoders, GANs and diffusion models\nNot 18\n19 Training and deploying TensorFlow models at scale"
  },
  {
    "objectID": "slides/1-welcome.html#extra-resources",
    "href": "slides/1-welcome.html#extra-resources",
    "title": "DAT255: Deep learning engineering",
    "section": "Extra resources",
    "text": "Extra resources\n\nFramework documentation:\n\nThe Keras documentation and examples\nThe TensorFlow documentation and examples\n\nVarious research blogs\nOther reputable internet material\n\nYou are expected to research certain topics and find supporting material yourself (especially for the project work)"
  },
  {
    "objectID": "slides/1-welcome.html#interaction",
    "href": "slides/1-welcome.html#interaction",
    "title": "DAT255: Deep learning engineering",
    "section": "Interaction",
    "text": "Interaction\n\n\n\nMuch of this course is based on gaining experience with deep learning by working on problems.\nOccationally we will ask YOU to share your experience by presenting your work in class.\n\nüë©‚Äçüíªü§ì"
  },
  {
    "objectID": "slides/1-welcome.html#assessment",
    "href": "slides/1-welcome.html#assessment",
    "title": "DAT255: Deep learning engineering",
    "section": "Assessment",
    "text": "Assessment\n\n\n\nThe exam has two parts:\n\nGroup project report, counts 50%\nShort written exam, counts 50%\n\nExam date will be posted on StudentWeb\nLast chance for registering for the exam is Feb.¬†2"
  },
  {
    "objectID": "slides/1-welcome.html#project-work",
    "href": "slides/1-welcome.html#project-work",
    "title": "DAT255: Deep learning engineering",
    "section": "Project work",
    "text": "Project work\nThe project work puts the engineering into Deep learning engineering\nPrimary goal:  Build and deploy a deep learning-based application, based on the theory, techniques and tools you learn in this course\n\n\n\nSecondary goals:  Make something that is\n\nUseful\nFun\nUseful and fun"
  },
  {
    "objectID": "slides/1-welcome.html#project-work-1",
    "href": "slides/1-welcome.html#project-work-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Project work",
    "text": "Project work\nThe project work puts the engineering into Deep learning engineering\nPrimary goal:  Build and deploy a deep learning-based application, based on the theory, techniques and tools you learn in this course\nTopic options:\n\nChoose yourself\nChoose from a project catalog (will be published on canvas)\n\nAll projects, along with a plan and description, must be approved beforehand\nüìÜ Submission deadline to be determined based on your input"
  },
  {
    "objectID": "slides/1-welcome.html#canvas",
    "href": "slides/1-welcome.html#canvas",
    "title": "DAT255: Deep learning engineering",
    "section": "Canvas",
    "text": "Canvas\nThe canonical source of information is Canvas"
  },
  {
    "objectID": "slides/1-welcome.html#calendar",
    "href": "slides/1-welcome.html#calendar",
    "title": "DAT255: Deep learning engineering",
    "section": "Calendar",
    "text": "Calendar"
  },
  {
    "objectID": "slides/1-welcome.html#deep-learning",
    "href": "slides/1-welcome.html#deep-learning",
    "title": "DAT255: Deep learning engineering",
    "section": "Deep learning",
    "text": "Deep learning"
  },
  {
    "objectID": "slides/1-welcome.html#ai-vs-ml-vs-dl",
    "href": "slides/1-welcome.html#ai-vs-ml-vs-dl",
    "title": "DAT255: Deep learning engineering",
    "section": "AI vs ML vs DL",
    "text": "AI vs ML vs DL\n\n\n\nWikiMedia Commons"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning",
    "title": "DAT255: Deep learning engineering",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\n\n\n\n\nArtificial neural network McCulloch & Pitts, 1943\n\n\n\n\\[\n\\small\na = \\sum_{i=1}^{M} w_ix_i\n\\] \\[\n\\small\ny = f(a)\n\\]"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-1",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\nThe perceptron Rosenblatt 1960\n\n\n\n\n\n\n\n\\[\n\\small\nf(a) =\n\\begin{cases}\n0, & a \\leq 0 \\\\\n1, & a &gt; 0\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-2",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-2",
    "title": "DAT255: Deep learning engineering",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\nBackpropagation Rumelhart, Hinton & Williams, 1986\n\n\nALVINN, 1989\n\n\n\n\n\n\n\nLeNet, 1989"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-3",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-3",
    "title": "DAT255: Deep learning engineering",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\n\n\nAlexNet, 2012"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-4",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-4",
    "title": "DAT255: Deep learning engineering",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\n\n\nLarge language models (LLMs), 2017\nGhatGPT 2022"
  },
  {
    "objectID": "slides/1-welcome.html#quick-history-of-deep-learning-5",
    "href": "slides/1-welcome.html#quick-history-of-deep-learning-5",
    "title": "DAT255: Deep learning engineering",
    "section": "Quick history of deep learning",
    "text": "Quick history of deep learning\n\n\nDiffusion models, 2020\n\n\n\nTF playground"
  },
  {
    "objectID": "slides/1-welcome.html#section-9",
    "href": "slides/1-welcome.html#section-9",
    "title": "DAT255: Deep learning engineering",
    "section": "",
    "text": "Maslej et al.¬†(2024) Artificial intelligence index report 2024. arXiv:2405.19522"
  },
  {
    "objectID": "slides/1-welcome.html#section-10",
    "href": "slides/1-welcome.html#section-10",
    "title": "DAT255: Deep learning engineering",
    "section": "",
    "text": "TensorFlowplayground"
  },
  {
    "objectID": "slides/3-convolutions.html#section",
    "href": "slides/3-convolutions.html#section",
    "title": "DAT255: Deep learning engineering",
    "section": "",
    "text": "TensorFlowplayground"
  },
  {
    "objectID": "slides/3-convolutions.html#shallow-learning",
    "href": "slides/3-convolutions.html#shallow-learning",
    "title": "DAT255: Deep learning engineering",
    "section": "Shallow learning",
    "text": "Shallow learning\n\n\n\n\n\n\n%%{ init: {'flowchart': { 'curve': 'bumpX', 'nodeSpacing': 50, 'rankSpacing': 80 } } }%%\nflowchart LR\n    X1(\"x1\") --&gt; M{\"Model _f_\"}\n    X2(\"x2\") --&gt; M\n    X1 --&gt; X3(\"x3\")\n    X2 --&gt; X3\n    X1 --&gt; X4(\"x4\")\n    X2 --&gt; X4\n    X3 --&gt; M\n    X4 --&gt; M\n    subgraph F[Original features]\n    X1\n    X2\n    end\n    subgraph FE[Engineered features]\n    X3\n    X4\n    end \n    M --&gt; P(\"Prediction _y_\")\n\nstyle F fill:#ededed,stroke:#606060\nstyle FE fill:#FFF8E1,stroke:#606060\n\n\n\n\n\n\n\n\\[\ny = f(x_1, x_2, x_3, x_4, \\dots, x_n | \\theta)\n\\]"
  },
  {
    "objectID": "slides/3-convolutions.html#deep-learning",
    "href": "slides/3-convolutions.html#deep-learning",
    "title": "DAT255: Deep learning engineering",
    "section": "Deep learning",
    "text": "Deep learning\n\n\n\n\n\n\n%%{ init: {'flowchart': { 'curve': 'bumpX', 'nodeSpacing': 50, 'rankSpacing': 80 } } }%%\nflowchart LR\n    X1(\"x1\") --&gt; L1(\"Layer 1 (_f1_)\")\n    X2(\"x2\") --&gt; L1\n    subgraph ML[Neural network]\n    L1 --&gt; L2(\"Layer 2 (_f2_)\")\n    L2 --&gt; L3(\"Layer 3 (_f3_)\")\n    end\n    subgraph F[Original features]\n    X1\n    X2\n    end\n    L3 --&gt; P(\"Prediction _y_\")\n\nstyle ML fill:#ededed,stroke:#606060\nstyle F fill:#ededed,stroke:#606060\n\n\n\n\n\n\n\n\\[\ny = f_3(f_2(f_1(x_1, x_2 | \\theta_1) | \\theta_2) | \\theta_3)\n\\]"
  },
  {
    "objectID": "slides/3-convolutions.html#section-1",
    "href": "slides/3-convolutions.html#section-1",
    "title": "DAT255: Deep learning engineering",
    "section": "",
    "text": "TensorFlowplayground"
  },
  {
    "objectID": "slides/3-convolutions.html#deep-learning-1",
    "href": "slides/3-convolutions.html#deep-learning-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Deep learning",
    "text": "Deep learning\n\n\n\nThe point of deep learning is to sequentially learn better feature representations, and use these to solve a task.\n\n\n\nSince neural networks are universal function approximators, they can model arbitrarily complex relationships. The cost of doing so, is that we need a lot of data."
  },
  {
    "objectID": "slides/3-convolutions.html#the-feed-forward-neural-network",
    "href": "slides/3-convolutions.html#the-feed-forward-neural-network",
    "title": "DAT255: Deep learning engineering",
    "section": "The feed-forward neural network",
    "text": "The feed-forward neural network\nFor the demo we used the good ol‚Äô fully-connected feed-forward network:\n\n\n\n\nEach node computes an output by\n\\[\n\\small\ny = f\\left( \\sum_{i=1}^{n} w_ix_i + b \\right)\n\\]\nwhere\n\n\\(w_i\\) is the weight of each incoming connection\n\\(b\\) is the bias term\n\\(f\\) is the activation function (more next week)"
  },
  {
    "objectID": "slides/3-convolutions.html#image-classification",
    "href": "slides/3-convolutions.html#image-classification",
    "title": "DAT255: Deep learning engineering",
    "section": "Image classification",
    "text": "Image classification\nLet‚Äôs classify this image: (see notebook 1)"
  },
  {
    "objectID": "slides/3-convolutions.html#image-classification-1",
    "href": "slides/3-convolutions.html#image-classification-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Image classification",
    "text": "Image classification\nLet‚Äôs classify this image: (see notebook 1)\nTry to treat every pixel as feature:\n\n\n2"
  },
  {
    "objectID": "slides/3-convolutions.html#image-classification-2",
    "href": "slides/3-convolutions.html#image-classification-2",
    "title": "DAT255: Deep learning engineering",
    "section": "Image classification",
    "text": "Image classification\nLet‚Äôs classify this image: (see notebook 1)\nTry to treat every pixel as feature:\n\n\nnot 2\n\n\nTwo obvious problems:\n\nNot invariant under translation(move the image  different result)\nNot invariant under dilation(resize the image  different result)"
  },
  {
    "objectID": "slides/3-convolutions.html#enter-the-convolution-operation",
    "href": "slides/3-convolutions.html#enter-the-convolution-operation",
    "title": "DAT255: Deep learning engineering",
    "section": "Enter the convolution operation",
    "text": "Enter the convolution operation\nThe foundation for modern computer vision (plus lots of other things!) is convolution:\nan operation that takes in two functions and returns a new function\n\n\n\n\n\n\\[\nf \\ast g \\equiv \\int_{-\\infty}^{\\infty} f(\\tau) g(t-\\tau) d\\tau\n\\]"
  },
  {
    "objectID": "slides/3-convolutions.html#enter-the-convolution-operation-1",
    "href": "slides/3-convolutions.html#enter-the-convolution-operation-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Enter the convolution operation",
    "text": "Enter the convolution operation\nThe foundation for modern computer vision (plus lots of other things!) is convolution:\nan operation that takes in two functions and returns a new function\n\n\n\n\n\n\\[\nf \\ast g \\equiv \\int_{-\\infty}^{\\infty} f(\\tau) g(t-\\tau) d\\tau\n\\]\n\n\n\nIn practice, convolution is a way to recognise and localise patterns in data"
  },
  {
    "objectID": "slides/3-convolutions.html#discrete-convolution",
    "href": "slides/3-convolutions.html#discrete-convolution",
    "title": "DAT255: Deep learning engineering",
    "section": "Discrete convolution",
    "text": "Discrete convolution\nConvolution is a lot easier with discrete data such as images, because:\n\nthe integral becomes a sum\nthe first function is our image\nthe second function is our kernel or filter, which tries to find patterns in the image."
  },
  {
    "objectID": "slides/3-convolutions.html#convolution-over-images",
    "href": "slides/3-convolutions.html#convolution-over-images",
    "title": "DAT255: Deep learning engineering",
    "section": "Convolution over images",
    "text": "Convolution over images\nSimple case ‚Äì one input channel"
  },
  {
    "objectID": "slides/3-convolutions.html#convolution-over-images-1",
    "href": "slides/3-convolutions.html#convolution-over-images-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Convolution over images",
    "text": "Convolution over images\nFor RGB color images: Process each color channel, then sum"
  },
  {
    "objectID": "slides/3-convolutions.html#the-convolution-kernel-or-filter",
    "href": "slides/3-convolutions.html#the-convolution-kernel-or-filter",
    "title": "DAT255: Deep learning engineering",
    "section": "The convolution kernel (or filter)",
    "text": "The convolution kernel (or filter)\nConvolution with predefined kernels is the core to digital image processing (but then we call it filters)\n\n\n\n\n\n\n\n\n\nIdentify vertical lines\n\n\n\n\n\n\n\nIdentify diagonal lines\n\n\n\n\n\n\n\nIdentifiy horizontal lines"
  },
  {
    "objectID": "slides/3-convolutions.html#more-filters",
    "href": "slides/3-convolutions.html#more-filters",
    "title": "DAT255: Deep learning engineering",
    "section": "More filters",
    "text": "More filters\n\n\nAverage: Blurring effect\n\n\n\n\n\n\n\n\nSobel filter: Edge detector"
  },
  {
    "objectID": "slides/3-convolutions.html#kernels-for-image-recognition",
    "href": "slides/3-convolutions.html#kernels-for-image-recognition",
    "title": "DAT255: Deep learning engineering",
    "section": "Kernels for image recognition",
    "text": "Kernels for image recognition\nLet‚Äôs try handcrafting some filters/kernels:\n\n\n\n\n\n\n\n\n\n\n\nNeed to refinethe approach :/"
  },
  {
    "objectID": "slides/3-convolutions.html#decomposition-into-simple-patters",
    "href": "slides/3-convolutions.html#decomposition-into-simple-patters",
    "title": "DAT255: Deep learning engineering",
    "section": "Decomposition into simple patters",
    "text": "Decomposition into simple patters\nA better approach: Multiple small filters\n\n\n\n\n\n\nOriginal image\n\n\nNew image, in lower resolution\n\n\nRepeat"
  },
  {
    "objectID": "slides/3-convolutions.html#decomposition-into-simple-patters-1",
    "href": "slides/3-convolutions.html#decomposition-into-simple-patters-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Decomposition into simple patters",
    "text": "Decomposition into simple patters"
  },
  {
    "objectID": "slides/3-convolutions.html#section-2",
    "href": "slides/3-convolutions.html#section-2",
    "title": "DAT255: Deep learning engineering",
    "section": "",
    "text": "Talk is cheap.Show me the code"
  },
  {
    "objectID": "slides/3-convolutions.html#keras-layers",
    "href": "slides/3-convolutions.html#keras-layers",
    "title": "DAT255: Deep learning engineering",
    "section": "Keras layers",
    "text": "Keras layers\nFor our proposed solution we need three layer types:\n\n\n\n\nConvolution layers to extract image features\nkeras.layers.Conv2D\n\n\n\n\n\nPooling layers to downsample and aggregate the features\nkeras.layers.MaxPooling2D\n\n\n\n\n\nFully-connected (dense) layers to compute the final prediction\nkeras.layers.Dense"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer",
    "href": "slides/3-convolutions.html#the-conv2d-layer",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer-1",
    "href": "slides/3-convolutions.html#the-conv2d-layer-1",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n\nNumber of filters to use (typical: 32 to 512)"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer-2",
    "href": "slides/3-convolutions.html#the-conv2d-layer-2",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n\nSize of the filter/kernel (typical: 3x3, sometimes bigger in the first layer)"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer-3",
    "href": "slides/3-convolutions.html#the-conv2d-layer-3",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n\nStepsize for the convolution operation (typical: 1 or 2)\n\n\n\n\n\n\n\n\n\nstride=(1,1)\n\n\n\n\n\n\n\n\n\nstride=(2,2)"
  },
  {
    "objectID": "slides/3-convolutions.html#the-conv2d-layer-4",
    "href": "slides/3-convolutions.html#the-conv2d-layer-4",
    "title": "DAT255: Deep learning engineering",
    "section": "The Conv2D layer",
    "text": "The Conv2D layer\n\n\nkeras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n\nPadding around the image edges (typical: 1 or 2)\n\n\n\n\n\n\n\n\n\npadding=\"valid\"\n\n\n\n\n\n\n\n\n\npadding=\"same\""
  },
  {
    "objectID": "slides/3-convolutions.html#pooling-layers",
    "href": "slides/3-convolutions.html#pooling-layers",
    "title": "DAT255: Deep learning engineering",
    "section": "Pooling layers",
    "text": "Pooling layers\nTwo reasons for downsampling the image features:\n\nLearn a spatial hierarchy by widening the receptive field\nReduce the total parameter count\n\nMost common approach: Choose the maximum value from a window of pixels"
  },
  {
    "objectID": "slides/3-convolutions.html#the-maxpooling2d-layer",
    "href": "slides/3-convolutions.html#the-maxpooling2d-layer",
    "title": "DAT255: Deep learning engineering",
    "section": "The MaxPooling2D layer",
    "text": "The MaxPooling2D layer\n\n\nkeras.layers.MaxPooling2D(\n    pool_size=(2, 2),\n    strides=None,\n    padding=\"valid\",\n    data_format=None, \n    name=None, \n    **kwargs\n)\n\npool_size: Size of pooling window (typical: 2x2 or 3x3)\nstrides: Step size (typical: same as pool_size)\npadding: Padding around edges, valid or same"
  },
  {
    "objectID": "slides/3-convolutions.html#the-dense-layer",
    "href": "slides/3-convolutions.html#the-dense-layer",
    "title": "DAT255: Deep learning engineering",
    "section": "The Dense layer",
    "text": "The Dense layer\n\n\nkeras.layers.Dense(\n    units,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    lora_rank=None,\n    **kwargs\n)\n\nunits: number of nodes in this layer\n\n\n\n\n\n\nIn the last dense layer, units must be equal to the number of classes (or otherwise number of desired outputs)."
  },
  {
    "objectID": "slides/3-convolutions.html#my-first-convolutional-network",
    "href": "slides/3-convolutions.html#my-first-convolutional-network",
    "title": "DAT255: Deep learning engineering",
    "section": "My first convolutional network ‚ú®",
    "text": "My first convolutional network ‚ú®\nLet‚Äôs piece together a convnet using Keras‚Äô sequential model API:\n\n\n\nconvnet = keras.Sequential(\n    [\n        keras.Input(shape=(28, 28, 1)),\n        keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        keras.layers.Flatten(),\n        keras.layers.Dense(10, activation=\"softmax\"),\n    ]\n)\n\n\n\n(More details about activations and training next week)"
  },
  {
    "objectID": "slides/3-convolutions.html#my-first-convolutional-network-1",
    "href": "slides/3-convolutions.html#my-first-convolutional-network-1",
    "title": "DAT255: Deep learning engineering",
    "section": "My first convolutional network ‚ú®",
    "text": "My first convolutional network ‚ú®\nconvnet.summary()\nModel: \"sequential_1\"\n\n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Layer (type)                         ‚îÉ Output Shape                ‚îÉ         Param # ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ conv2d (Conv2D)                      ‚îÇ (None, 26, 26, 32)          ‚îÇ             320 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d (MaxPooling2D)         ‚îÇ (None, 13, 13, 32)          ‚îÇ               0 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_1 (Conv2D)                    ‚îÇ (None, 11, 11, 32)          ‚îÇ           9,248 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_1 (MaxPooling2D)       ‚îÇ (None, 5, 5, 32)            ‚îÇ               0 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ flatten_1 (Flatten)                  ‚îÇ (None, 800)                 ‚îÇ               0 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dropout (Dropout)                    ‚îÇ (None, 800)                 ‚îÇ               0 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dense_3 (Dense)                      ‚îÇ (None, 10)                  ‚îÇ           8,010 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n Total params: 17,578 (68.66 KB)\n\n Trainable params: 17,578 (68.66 KB)\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "slides/3-convolutions.html#my-first-convolutional-network-2",
    "href": "slides/3-convolutions.html#my-first-convolutional-network-2",
    "title": "DAT255: Deep learning engineering",
    "section": "My first convolutional network ‚ú®",
    "text": "My first convolutional network ‚ú®\nConfigure the training objective and strategy:\nconvnet.compile(\n  loss=\"categorical_crossentropy\",\n  optimizer=\"adam\",\n  metrics=[\"accuracy\"]\n)\n(again, more details next week)\nStart training!\nconvnet.fit(\n  X_train,\n  y_train,\n  batch_size=128,\n  epochs=15,\n  validation_split=0.1\n)"
  },
  {
    "objectID": "slides/3-convolutions.html#decomposition-into-simple-patters-theory-vs-practice",
    "href": "slides/3-convolutions.html#decomposition-into-simple-patters-theory-vs-practice",
    "title": "DAT255: Deep learning engineering",
    "section": "Decomposition into simple patters: Theory vs practice",
    "text": "Decomposition into simple patters: Theory vs practice\nRemember the cat:\n\n\n\n\n\n(We‚Äôll try to classify pictures of cats in exercise 3, but let‚Äôs test out a cat detector convnet already now)"
  },
  {
    "objectID": "slides/3-convolutions.html#decomposition-into-simple-patters-theory-vs-practice-1",
    "href": "slides/3-convolutions.html#decomposition-into-simple-patters-theory-vs-practice-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Decomposition into simple patters: Theory vs practice",
    "text": "Decomposition into simple patters: Theory vs practice\nOur test image:\n\n\n\n\n\n\nFrom F. Chollet: Deep Learning with Python"
  },
  {
    "objectID": "slides/3-convolutions.html#layer-activations",
    "href": "slides/3-convolutions.html#layer-activations",
    "title": "DAT255: Deep learning engineering",
    "section": "Layer activations",
    "text": "Layer activations\nWe can visualise what each filter does by looking at its activation on the test image: The output after the convolution and applying the activation function.\nExamples:\n\n\n\n\n\n\n\n\n\nLayer 1, filter 4\n\n\n\n\n\n\n\nLayer 1, filter 7"
  },
  {
    "objectID": "slides/3-convolutions.html#layer-activations-1",
    "href": "slides/3-convolutions.html#layer-activations-1",
    "title": "DAT255: Deep learning engineering",
    "section": "Layer activations",
    "text": "Layer activations\nRepeat for all filters in all layers:\nLayer 1 and 2:"
  },
  {
    "objectID": "slides/3-convolutions.html#layer-activations-2",
    "href": "slides/3-convolutions.html#layer-activations-2",
    "title": "DAT255: Deep learning engineering",
    "section": "Layer activations",
    "text": "Layer activations\nRepeat for all filters in all layers:\nLayer 3:"
  },
  {
    "objectID": "slides/3-convolutions.html#layer-activations-3",
    "href": "slides/3-convolutions.html#layer-activations-3",
    "title": "DAT255: Deep learning engineering",
    "section": "Layer activations",
    "text": "Layer activations\nRepeat for all filters in all layers:\nLayer 4 (last):"
  }
]