{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d2db3b5",
   "metadata": {},
   "source": [
    "A.S. Lundervold, 08.02.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef348a8-18cc-431b-b6d8-0970f7c2f9cc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The building blocks of neural networks, Part 1: Tensors and tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70642d1-b27c-4588-8539-05d6c08daacf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> This two-part tutorial is meant to increase your familiarity with the basics of PyTorch and the basic building blocks of artificial neural networks. \n",
    "\n",
    "> This notebook is partly based on Chapter 2 of Chollet's text book \"Deep learning with Python\", 2nd edition: https://livebook.manning.com/book/deep-learning-with-python-second-edition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f189ef-1112-481a-9b36-5a4c5d774bc4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As deep neural networks consist of a set of chained operations on what's called _tensors_, we'll take a closer look at _tensors_ and _tensor operations_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e120ee-0d54-4bf4-b17a-ef3ab4097ca6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Plan:**\n",
    "\n",
    "1. Define tensors\n",
    "2. Vocabulary and examples\n",
    "3. Tensor operations\n",
    "4. A quick linear algebra refresher: geometric interpretations of tensor operations\n",
    "\n",
    "\n",
    "**Takeaway**:\n",
    "\n",
    "> Our main takeaway will be that **deep neural networks can be viewed as a long chain of geometric transformations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69478538-e765-4152-84c5-ac05bf146039",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0bfe04a-7650-4008-8f0c-e4eb0d4ba67f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is a quick check of whether the notebook is currently running on Google Colaboratory\n",
    "# or on Kaggle, as that makes some difference for the code below.\n",
    "try:\n",
    "    import colab\n",
    "    colab=True\n",
    "except:\n",
    "    colab=False\n",
    "\n",
    "import os\n",
    "kaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307ef235-68a7-4b79-aeba-e9510a95cc62",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if (colab or kaggle):\n",
    "    !pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fb68af-895d-4927-b784-ec9764775c9a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, matplotlib.pyplot as plt, pandas as pd, sklearn.datasets\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29b4bd-5fd2-4501-b5ff-5effe84da63c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Set up data directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fadf9744-bb11-4bd2-a220-4b914e3fe87b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NB_DIR = Path.cwd()\n",
    "# Change this if you want to store the images that are downloaded\n",
    "# below elsewhere on your computer.\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    DATADIR = Path(\"/content/gdrive/MyDrive/Colab Notebooks/data\")\n",
    "    DATADIR.mkdir(exist_ok=True)\n",
    "if not colab:\n",
    "    DATADIR = Path.home()/'data'\n",
    "    DATADIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f18ee9-c797-4144-8bda-206d087a19c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b6296-5a5a-46a2-9e34-82c38f4c2a7a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92dc3558-af5d-402a-bea8-8fa6bfcb7b76",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mnist = torchvision.datasets.MNIST(root=DATADIR, train=True, download=True, transform=transform)\n",
    "cifar = torchvision.datasets.CIFAR10(root=DATADIR, train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d84eabda-a7ae-479f-bc1b-937ade543ade",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "housing = sklearn.datasets.fetch_california_housing()\n",
    "\n",
    "housing_df = pd.DataFrame(housing.data, columns=housing.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873f5afe-9d57-4a3b-aa39-8d80ba80de07",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d2314-28c6-43d8-871b-f28430f63758",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Tensors are multidimensional arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054eeb66-a2e5-4ce4-b790-340650fac370",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Vocabulary: the rank of a tensor\n",
    "\n",
    "The **rank** of a tensor is the **number of axes**. In Pytorch this is called the **number of dimensions**, or `ndim`. \n",
    "\n",
    "The **shape** of a tensor is the number of dimensions along each axis.\n",
    "\n",
    "The **data type** of a tensor is the data type of the data in the tensor. As opposed to more general arrays (like f.ex. NumPy arrays), a tensor has to have the same datatype for all its items. This combined with GPUs or other accelerators make linear algebra computations immensely more efficient using tensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3939ce2-eac2-4c67-b6f5-db975f033e5c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Rank 0 tensors: scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f683707-44d4-427a-950f-e832eae35eff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Rank 0 tensors stores scalars (integers or floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15753a2a-336d-4e23-b55c-c7f5248c2485",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = 42\n",
    "\n",
    "tns = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e072761-20a6-40c7-964c-d65ebba4b78a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa0fca1-e311-4da8-bfa5-c00b9807adb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4cfe38-1c5f-4554-825f-4488dad3e283",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0331e80-107d-4e1d-ba8e-98dfa22b3885",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7fc56b-8e92-4d10-9acb-b1a22a22b73b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Rank 1 tensors: vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1aa239-48e9-4742-9465-cc9e80455012",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Rank 1 tensors are _vectors_ or _arrays of numbers_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d5f64e-038c-4808-a973-dfc49492bc55",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = [12,13,14]\n",
    "\n",
    "tns = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32962029-782b-4318-a056-6f2a7dfa6dc0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 13, 14])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70ecf66b-62f3-4abc-9674-5b44b7f97977",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "541ce33a-4277-44c4-b301-0ecb77a7a776",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9c1fe57-4aaf-424a-951a-f8b9e8dda5cc",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad922cca-f2d3-4732-bcc9-6b1dd74de88d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **Warning:** When speaking about vectors, the **dimension of a vector** is the number of entries in the vector. This can be a bit confusing. The number of dimensions of the vector [1,2,3] is 3, while its dimension as a tensor is 1. It is therefore safer to use the word **rank** when referring to the tensor dimension (as in, [1,2,3] is a rank 1 tensor). In other words, it has only one **axis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a1e4b-a355-45fe-a9ab-5f1037329a56",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4956f611-a987-4080-b3c3-0bf1267fa755",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You'll often deal with rank 1 tensors. For example, each instance of a tabular data set can be represented as vectors containing all the corresponding feature values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aae55c7d-17fc-4b4c-a344-61526b991400",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.02381</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127    1.02381       322.0  2.555556     37.88   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338095d1-6889-43e1-8558-8897646e5878",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Rank 2 tensors: matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46750a19-8c6e-4289-86b4-734730ee1179",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Rank 2 tensors are what corresponds to standard 2D matrices or arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2209a24b-4d0f-4dc3-9567-1f14837ccdf1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = [[12,13,14], [15,16,17]]\n",
    "\n",
    "tns = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "634f647e-8fb8-46e7-84ef-433048d945b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 13, 14],\n",
       "        [15, 16, 17]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d97624ec-74fa-4219-af68-96946ee0a40c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62d5977f-441c-4227-837e-01c8a132fb03",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaa1ba05-b028-49be-a9f0-3046ca1ea3e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb8f14-e0f9-47d4-a52c-ce1ee1a99764",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c9042-c3e4-41a2-a944-22a377c4e29a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A common way to end up with rank 2 tensors in machine learning is as representation of tabular data sets. Each data instance consists of a vector (rank 1 tensor) containing feature values (think price, color, age, etc), and a batch of data is a number of such instances. \n",
    "\n",
    "You end up with a matrix where the first axis is the sample axis and the second axis is the feature axis: (`samples`, `features`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ffda99f-21ea-478b-933d-225c8ad265c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcd6c235-271f-476b-a2fd-603de7d8ecd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tns = torch.tensor(housing.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "604ff809-3c2e-4721-9836-6939fe341cde",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   8.3252,   41.0000,    6.9841,  ...,    2.5556,   37.8800,\n",
       "         -122.2300],\n",
       "        [   8.3014,   21.0000,    6.2381,  ...,    2.1098,   37.8600,\n",
       "         -122.2200],\n",
       "        [   7.2574,   52.0000,    8.2881,  ...,    2.8023,   37.8500,\n",
       "         -122.2400],\n",
       "        ...,\n",
       "        [   1.7000,   17.0000,    5.2055,  ...,    2.3256,   39.4300,\n",
       "         -121.2200],\n",
       "        [   1.8672,   18.0000,    5.3295,  ...,    2.1232,   39.4300,\n",
       "         -121.3200],\n",
       "        [   2.3886,   16.0000,    5.2547,  ...,    2.6170,   39.3700,\n",
       "         -121.2400]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cf23aa3-c9fa-4ce8-8774-f3dafaa4c8f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20640, 8])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71312739-1cce-450f-961e-de38acf88160",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72815551-14f8-4e92-97bd-41466904076b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97eda32-6a29-4a57-951f-c33e59920483",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another way to end up with rank 2 tensors are time series or sequence data: (`timesteps`,`features`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffad0b3-cc6e-4d95-ad62-e2104635f9b6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Tensors of rank 3 and more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f29140-9db0-44bf-8ff1-717c6bcf1b23",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you stack several rank 2 tensors you'll obtain a rank 3 tensor. If you stack rank 3 tensors, you'll have a rank 4 tensor. And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08372625-d36f-4032-b0e9-aa2d78450977",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tns1 = torch.tensor(\n",
    "            [[1,2,3], [4,5,6]]\n",
    "        )\n",
    "\n",
    "tns2 = torch.tensor(\n",
    "            [[7,8,9], [10,11,12]]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7aabd28-2552-42d5-bb68-952aa6519f8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a711f76-bbc2-4bd5-a699-62c4e25da667",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "702c8ae5-003d-42dc-8adc-8ad053d0ec28",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns1.ndim, tns2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6f4d4df-cec9-4188-b317-e2e0b975d10b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tns = torch.stack((tns1, tns2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "597f62b0-311a-42ce-a89e-a6d45cfd7ba0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f39f313-872a-4f85-8d2b-170a2f4f922c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf7905b5-ab82-4e74-8979-a386bb9e91f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cf771f4-d24e-4cda-8d05-08ed5eaa61af",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tns4 = torch.stack((tns, tns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "890e80bf-973d-41e4-bdb6-1fd37df1c419",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns4.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d686e-3bdd-49b7-a38f-c479f7578efd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8583b-4aaa-4350-be4e-d3cad9fab643",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you're dealing with **time series or sequence data** (i.e., where each instance is a rank 2 tensor (`timesteps`,`features`), you'll end up with rank 3 tensors: (`samples`, `timesteps`, `features`). \n",
    "\n",
    "Individual **images** are also typically represented as rank 3 tensors. The three axes of an image tensor is height, width and channel (typically color channel): (`height`, `width`, `channels`). For color images, the three channels are typically R, G and B. For grayscale images one typically inserts a single channel axis.\n",
    "\n",
    "If you're dealing with image data consisting of multiple images then you'll typically represent your data as rank 4 tensors: (`samples`, `height`, `width`, `channels`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b244ae7f-25a5-4386-be8a-dc28ea63323e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9831f57-b2e9-4727-a126-3b99c6ed9f4c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar.data[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6aa990d5-5b1a-433c-bc39-6009ec6f9707",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8266b067-0061-4b35-974e-fbd1e5409d99",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnist_example = mnist.data[0].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd23c1de-214c-4c09-b991-56b04bc3e01c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87720284-6cb3-4191-af14-661833369350",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_example.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f287f414-2b43-4eae-8b10-425dd4dd6acd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A batch of images will then be a rank 4 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d8056c9-38a4-4bc7-bd48-36c277454250",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "912681ed-6b24-4d62-90bd-14f29cc3bd3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar.data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22880b44",
   "metadata": {},
   "source": [
    "#### 3D images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb69346",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c5/MRI_brain_sagittal_section.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38543c9-e534-45ed-b912-c30a45b2f018",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03aeb59-2abf-4fda-a10d-3be409fdbcfb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A video is a series of image frames. As the images are rank 3 tensors, a video can be represented as a rank 4 tensor by stacking the frames. A batch of videos will then be a rank 5 tensor: \n",
    "\n",
    "`(samples, frames, height, width, color_depth)` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7eb31b-9209-49a3-8809-1ea285ed2212",
   "metadata": {},
   "source": [
    "# Tensor operations and linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69049a7-e1e4-4952-9395-3a61d145618f",
   "metadata": {},
   "source": [
    "All the operations in a deep neural network are based on a few simple tensor operations, like addition, multiplication and simple nonlinear functions applied to tensors. \n",
    "\n",
    "Since tensors are multidimensional arrays. Therefore, **linear algebra** is at the heart of deep learning. As linear algebra is very **geometric**, this gives us a geometric point of view for deep learning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c75407a027d59d8279fdc80f39ae7e88eaf5822626513196156b9ba3e7422158"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
