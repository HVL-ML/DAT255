{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Predict rail and bus travellers using RNNs\n",
        "\n",
        "In this notebook we'll try to predict the number of passengers on bus and railroad transport in Chicago, by looking at historical time series data. This task is also described in the \"Hands-on Machine Learning\" book by A. Geron (that we used in DAT158), so you can also study chapter 15 there for more details."
      ],
      "metadata": {
        "id": "_GNJicW6GN4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "ie9UvnQEGweG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data"
      ],
      "metadata": {
        "id": "Wkuss1FcG7Ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = keras.utils.get_file(\n",
        "    \"ridership.tgz\",\n",
        "    \"https://github.com/ageron/data/raw/main/ridership.tgz\",\n",
        "    cache_dir=\".\",\n",
        "    extract=True\n",
        ")\n",
        "if \"_extracted\" in filepath:\n",
        "    ridership_path = Path(filepath) / \"ridership\"\n",
        "else:\n",
        "    ridership_path = Path(filepath).with_name(\"ridership\")\n",
        "\n"
      ],
      "metadata": {
        "id": "s4_mOGAcG6up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls datasets/ridership_extracted/ridership/"
      ],
      "metadata": {
        "id": "N1Fwa3xgHD-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have a quick look at the contents of the CSV file."
      ],
      "metadata": {
        "id": "ogUsyv8aLRot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! head datasets/ridership_extracted/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv"
      ],
      "metadata": {
        "id": "nb7SaQ8yHhu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we will be dealing with CSV data both in this notebook an the next one, we can use the Pandas library to get some convenience functions."
      ],
      "metadata": {
        "id": "NEUTMBP0Ldw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas"
      ],
      "metadata": {
        "id": "OH7KfzsaLpw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the file."
      ],
      "metadata": {
        "id": "bo3J4nv_LwzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = Path(\"datasets/ridership_extracted/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv\")\n",
        "df = pd.read_csv(path, parse_dates=[\"service_date\"])\n",
        "df.columns = [\"date\", \"day_type\", \"bus\", \"rail\", \"total\"]  # shorter names\n",
        "df = df.sort_values(\"date\").set_index(\"date\")\n",
        "df = df.drop(\"total\", axis=1)\n",
        "df = df.drop_duplicates()  # remove duplicated months (2011-10 and 2014-07)"
      ],
      "metadata": {
        "id": "ZQx1hX73L0yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if this looks like what we printed before:"
      ],
      "metadata": {
        "id": "NOeRyJ8pL_mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Nh6cyVe0MIQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investigate the data\n",
        "\n",
        "Let's look at the first few months of 2019 (note that Pandas treats the range boundaries as inclusive):"
      ],
      "metadata": {
        "id": "8x-_BtOuMMB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"2019-03\":\"2019-04\"].plot(grid=True, marker=\".\", figsize=(8, 5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y9FrQbggMNyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's look at the difference between each time step and the same day last week. We can compute this by using the `diff` function.\n",
        "\n",
        "Does it look like there is always the same number of travellers each Tuesday?\n"
      ],
      "metadata": {
        "id": "NXDHKGicMVEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# `.diff(7)` means we use a 7 day lag\n",
        "diff_7 = df[[\"bus\", \"rail\"]].diff(7)[\"2019-03\":\"2019-05\"]\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(8, 5))\n",
        "\n",
        "df.plot(ax=axs[0], legend=False, marker=\".\")  # original time series\n",
        "df.shift(7).plot(ax=axs[0], grid=True, legend=False, linestyle=\":\")  # lagged\n",
        "diff_7.plot(ax=axs[1], grid=True, marker=\".\")  # 7-day difference time series\n",
        "\n",
        "axs[0].set_ylim([170_000, 900_000])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZA5M-CGbMawV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(df.loc[\"2019-05-25\":\"2019-05-27\"][\"day_type\"])"
      ],
      "metadata": {
        "id": "l6gXkWPcMUri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple prediction\n",
        "\n",
        "Is the number of travellers on the same day last week, a good estimate of the number of travellers today? Compute the mean absolute error (MAE).\n"
      ],
      "metadata": {
        "id": "Uxw2mHNOMuOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff_7.abs().mean()"
      ],
      "metadata": {
        "id": "FZ3f2GBwMxQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And mean absolute percentage error (MAPE):"
      ],
      "metadata": {
        "id": "i5PkPJNrMzYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = df[[\"bus\", \"rail\"]][\"2019-03\":\"2019-05\"]\n",
        "(diff_7 / targets).abs().mean()"
      ],
      "metadata": {
        "id": "_auiJDfpM2S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look at the yearly seasonality and the long-term trends:"
      ],
      "metadata": {
        "id": "27oeLmk5M8mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "period = slice(\"2001\", \"2019\")\n",
        "\n",
        "df_monthly = df.select_dtypes(include=\"number\").resample('ME').mean()  # compute the mean for each month\n",
        "rolling_average_12_months = df_monthly.loc[period].rolling(window=12).mean()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "df_monthly[period].plot(ax=ax, marker=\".\")\n",
        "rolling_average_12_months.plot(ax=ax, grid=True, legend=False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sXUbOg3yM-FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_monthly.diff(12)[period].plot(grid=True, marker=\".\", figsize=(8, 3))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C1DGB58yMr9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Build an ARIMA model\n",
        "\n",
        "If you want, try also to compare to a \"traditional\" statistical model, like [ARIMA](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average) (autoregressive integrated moving average).\n",
        "\n",
        "For this we need the `statsmodels` library:\n"
      ],
      "metadata": {
        "id": "Xwv1cwk9NGaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install statsmodels"
      ],
      "metadata": {
        "id": "YIVC_kqSNgGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "origin, today = \"2019-01-01\", \"2019-05-31\"\n",
        "rail_series = df.loc[origin:today][\"rail\"].asfreq(\"D\")\n",
        "\n",
        "model = ARIMA(\n",
        "    rail_series,\n",
        "    order=(1, 0, 0),\n",
        "    seasonal_order=(0, 1, 1, 7)\n",
        ")\n",
        "\n",
        "model = model.fit()\n",
        "\n",
        "y_pred = model.forecast()  # should return 427,758.6"
      ],
      "metadata": {
        "id": "-HYi9tjANkS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[0]  # ARIMA forecast"
      ],
      "metadata": {
        "id": "oh-CESeoNt2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"rail\"].loc[\"2019-06-01\"]  # target value"
      ],
      "metadata": {
        "id": "Xsz35mmaNwDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"rail\"].loc[\"2019-05-25\"]  # naive forecast (value from one week earlier)"
      ],
      "metadata": {
        "id": "khssszZ_NxoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the mean average error for the ARIMA model:"
      ],
      "metadata": {
        "id": "Us_34kEYNzqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin, start_date, end_date = \"2019-01-01\", \"2019-03-01\", \"2019-05-31\"\n",
        "time_period = pd.date_range(start_date, end_date)\n",
        "rail_series = df.loc[origin:end_date][\"rail\"].asfreq(\"D\")\n",
        "\n",
        "y_preds = []\n",
        "for today in time_period.shift(-1):\n",
        "    model = ARIMA(rail_series[origin:today],  # train on data up to \"today\"\n",
        "                  order=(1, 0, 0),\n",
        "                  seasonal_order=(0, 1, 1, 7))\n",
        "    model = model.fit()  # note that we retrain the model every day!\n",
        "    y_pred = model.forecast().iloc[0]\n",
        "    y_preds.append(y_pred)\n",
        "\n",
        "y_preds = pd.Series(y_preds, index=time_period)\n",
        "\n",
        "mae = (y_preds - rail_series[time_period]).abs().mean()  # should return 32,040.7"
      ],
      "metadata": {
        "id": "VfZne5A6N1Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('ARIMA model MAE:', mae)"
      ],
      "metadata": {
        "id": "AXCkCFUrN66o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the ARIMA forecast:"
      ],
      "metadata": {
        "id": "Mlu7dYfgOEJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 3))\n",
        "rail_series.loc[time_period].plot(label=\"True\", ax=ax, marker=\".\", grid=True)\n",
        "ax.plot(y_preds, color=\"r\", marker=\".\", label=\"ARIMA forecasts\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IauoilTiOGS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (end of optional part)"
      ],
      "metadata": {
        "id": "MJJKeHHzOLH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `tf.data.Dataset` with time series\n",
        "\n",
        "Once we have the data loaded as a NumPy array, we can convert it into a batched TensorFlow dataset using the `timeseries_dataset_from_array` utility function."
      ],
      "metadata": {
        "id": "VQjRVfSQOPcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, to get even more feel to how `timeseries_dataset_from_array` works, let's print some values from a \"dummy\" example:"
      ],
      "metadata": {
        "id": "vLRF-c5ZOg40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_series = [0, 1, 2, 3, 4, 5]\n",
        "my_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    my_series,\n",
        "    targets=my_series[3:],  # the targets are 3 steps into the future\n",
        "    sequence_length=3,\n",
        "    batch_size=2\n",
        ")\n",
        "\n",
        "as_list = list(my_dataset)\n",
        "for x, y in as_list:\n",
        "    print('x:', x.numpy(), 'y:', y.numpy())"
      ],
      "metadata": {
        "id": "ZP5KM4ucOvDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok. Before we continue looking at the data, let's split the time series into three periods, for training, validation and testing. We won't look at the test data for now."
      ],
      "metadata": {
        "id": "xHvTtBtvO7u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rail_train = df[\"rail\"][\"2016-01\":\"2018-12\"] / 1e6      # here we also scale the data\n",
        "rail_valid = df[\"rail\"][\"2019-01\":\"2019-05\"] / 1e6\n",
        "rail_test = df[\"rail\"][\"2019-06\":] / 1e6"
      ],
      "metadata": {
        "id": "cx1khJTwPA24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the datasets -- but for now, we stick to only the rail data."
      ],
      "metadata": {
        "id": "AHUNXNp6Qo-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 56\n",
        "tf.random.set_seed(42)  # for reproducibility\n",
        "\n",
        "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    rail_train.to_numpy(),\n",
        "    targets=rail_train[seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    rail_valid.to_numpy(),\n",
        "    targets=rail_valid[seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "11leGWNFPK8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a simple dense network\n",
        "\n",
        "For our first network, we try a dead simple approach with a single `Dense` layer.\n"
      ],
      "metadata": {
        "id": "Z151Zp5kPP94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Input(shape=(seq_length,)),\n",
        "        keras.layers.Dense(1)\n",
        "    ]\n",
        ")\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_mae\",\n",
        "    patience=20,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.02)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.Huber(),\n",
        "    optimizer=opt,\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    epochs=200,\n",
        "    callbacks=[early_stopping_cb]\n",
        ")"
      ],
      "metadata": {
        "id": "vK8ClANHPUdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the prediction preformance:"
      ],
      "metadata": {
        "id": "uFQux8kFPoVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss, valid_mae = model.evaluate(valid_ds, verbose=0)\n",
        "print('Validation MAE:', valid_mae * 1e6)   # (remember to multiply with 1e6 since we scaled the data)"
      ],
      "metadata": {
        "id": "dY88sFHNPqg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a simple RNN"
      ],
      "metadata": {
        "id": "lhRTD9zsPzC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to compare many different model types. Let's first define a utility function to train and evaluate each model."
      ],
      "metadata": {
        "id": "ESwAeEeOQCGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=200):\n",
        "\n",
        "    early_stopping_cb = keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_mae\",\n",
        "        patience=20,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        loss=keras.losses.Huber(),\n",
        "        optimizer=opt,\n",
        "        metrics=[\"mae\"]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_set,\n",
        "        validation_data=valid_set,\n",
        "        epochs=epochs,\n",
        "        callbacks=[early_stopping_cb]\n",
        "    )\n",
        "\n",
        "    valid_loss, valid_mae = model.evaluate(valid_set)\n",
        "    return valid_mae * 1e6"
      ],
      "metadata": {
        "id": "7SX0nNe7QPVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the simple RNN model, and evaluate it."
      ],
      "metadata": {
        "id": "p2zjs9lRQV6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Input(shape=(None, 1)),\n",
        "        keras.layers.SimpleRNN(1)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "MumivCZzP0yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_and_evaluate(model, train_ds, valid_ds, learning_rate=0.02)"
      ],
      "metadata": {
        "id": "aCO723XXQbiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a second, simple RNN\n",
        "\n",
        "Let's try again, but adding a `Dense` output layer."
      ],
      "metadata": {
        "id": "xN_g9RhhRFNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "univariate_model = tf.keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Input(shape=(None, 1)),\n",
        "        tf.keras.layers.SimpleRNN(32),\n",
        "        tf.keras.layers.Dense(1)  # no activation function by default\n",
        "])"
      ],
      "metadata": {
        "id": "reod0AYjRMpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_and_evaluate(univariate_model, train_ds, valid_ds, learning_rate=0.02)"
      ],
      "metadata": {
        "id": "lsQfx-27RbKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How did this compare?"
      ],
      "metadata": {
        "id": "ITxA47y1Q7nF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a deep RNN\n",
        "\n",
        "### Exercise:\n",
        "\n",
        "This model won't run, because we have forgotten some arguments to the stacked SimpleRNN layers. Fix them, and run the model."
      ],
      "metadata": {
        "id": "Wri_eWinRfy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deep_model = tf.keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Input(shape=(None, 1)),\n",
        "        tf.keras.layers.SimpleRNN(32),\n",
        "        tf.keras.layers.SimpleRNN(32),\n",
        "        tf.keras.layers.SimpleRNN(32),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "GjcxN4g-R3cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_and_evaluate(deep_model, train_ds, valid_ds, learning_rate=0.01)"
      ],
      "metadata": {
        "id": "cwgyoEGRR_jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multivariate time series\n",
        "\n",
        "Since we have additional observables in the dataset (day type and bus travels), we can add those to out model too, and se if the results improve:\n"
      ],
      "metadata": {
        "id": "yUsgciVZR_Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_mulvar = df[[\"bus\", \"rail\"]] / 1e6  # use both bus & rail series as input\n",
        "df_mulvar[\"next_day_type\"] = df[\"day_type\"].shift(-1)  # we know tomorrow's type\n",
        "df_mulvar = pd.get_dummies(df_mulvar, dtype=float)  # one-hot encode the day type"
      ],
      "metadata": {
        "id": "nzHqE9ENSKaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mulvar_train = df_mulvar[\"2016-01\":\"2018-12\"]\n",
        "mulvar_valid = df_mulvar[\"2019-01\":\"2019-05\"]\n",
        "mulvar_test = df_mulvar[\"2019-06\":]"
      ],
      "metadata": {
        "id": "IejO4Kl5SNU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_train.to_numpy(),  # use all 5 columns as input\n",
        "    targets=mulvar_train[\"rail\"][seq_length:],  # forecast only the rail series\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "valid_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_valid.to_numpy(),\n",
        "    targets=mulvar_valid[\"rail\"][seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "3tecAUNxSPtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Exercise:\n",
        "\n",
        "Implement a single-layer RNNs as before, which now has the correct input shape to match the new dataset.\n"
      ],
      "metadata": {
        "id": "lMrjk2beSTs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multivar_model = tf.keras.Sequential([\n",
        "    ...\n",
        "])"
      ],
      "metadata": {
        "id": "VFuIfTZwSWVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_and_evaluate(\n",
        "    multivar_model,\n",
        "    train_mulvar_ds,\n",
        "    valid_mulvar_ds,\n",
        "    learning_rate=0.05\n",
        ")"
      ],
      "metadata": {
        "id": "P4KgL3-tSYAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding multiple targets to our dataset\n",
        "\n",
        "Now we try and predict both the number of rail passengers and bus passengers at the same time.\n"
      ],
      "metadata": {
        "id": "wiPHjZDQSjzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 56\n",
        "\n",
        "train_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_train.to_numpy(),\n",
        "    targets=mulvar_train[[\"bus\", \"rail\"]][seq_length:],  # 2 targets per day\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "valid_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_valid.to_numpy(),\n",
        "    targets=mulvar_valid[[\"bus\", \"rail\"]][seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "9SEex2nCSnh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise:\n",
        "\n",
        "Again make a simple RNN network, which now can predict two outputs."
      ],
      "metadata": {
        "id": "0zBn4ufhWW4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multitask_model = tf.keras.Sequential([\n",
        "    ...\n",
        "])\n",
        "\n",
        "fit_and_evaluate(\n",
        "    multitask_model,\n",
        "    train_multask_ds,\n",
        "    valid_multask_ds,\n",
        "    learning_rate=0.02\n",
        ")"
      ],
      "metadata": {
        "id": "AQ58yVQ3Sthx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forecasting several steps ahead\n",
        "\n",
        "Let's try to expand our forecast, by forecasting day by day  for multiple days."
      ],
      "metadata": {
        "id": "vyC0oeQ3TPp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = rail_valid.to_numpy()[np.newaxis, :seq_length, np.newaxis]\n",
        "for step_ahead in range(14):\n",
        "    y_pred_one = univariate_model.predict(X)\n",
        "    X = np.concatenate([X, y_pred_one.reshape(1, 1, 1)], axis=1)"
      ],
      "metadata": {
        "id": "-JYJ1NTATi6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The forecasts start on 2019-02-26, as it is the 57th day of 2019, and they end\n",
        "# on 2019-03-11. That's 14 days in total.\n",
        "\n",
        "Y_pred = pd.Series(\n",
        "    X[0, -14:, 0],\n",
        "    index=pd.date_range(\"2019-02-26\", \"2019-03-11\")\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 3.5))\n",
        "\n",
        "(rail_valid * 1e6)[\"2019-02-01\":\"2019-03-11\"].plot(\n",
        "    label=\"True\", marker=\".\", ax=ax)\n",
        "\n",
        "(Y_pred * 1e6).plot(\n",
        "    label=\"Predictions\", grid=True, marker=\"x\", color=\"r\", ax=ax)\n",
        "\n",
        "ax.vlines(\"2019-02-25\", 0, 1e6, color=\"k\", linestyle=\"--\", label=\"Today\")\n",
        "ax.set_ylim([200_000, 800_000])\n",
        "plt.legend(loc=\"center left\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iUEngfERTk69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Open exercises\n",
        "\n",
        "Since we already know that the `SimpleRNN` layer is a bit too simplistic, try to make two improved models:\n",
        "- One using [`LSTM` layers](https://keras.io/api/layers/recurrent_layers/lstm/)\n",
        "- One using [`GRU` layers](https://keras.io/api/layers/recurrent_layers/gru/)\n",
        ""
      ],
      "metadata": {
        "id": "2n2TSGEIWt0i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wK27w9o-XOJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}