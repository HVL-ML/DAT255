{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy a model as a REST API using TensorFlow Serving\n",
        "\n",
        "In this notebook we will set up a REST API where we can send a request containing an image, and receive a classification in return.\n",
        "\n",
        "In practice we would of course not run our endpoint service in a notebook, but we can still use a notebook to illustrate the procedure. To run the code we have to install TensorFlow Serving, which in the code below assumes that we are on a Debian-type system. This is the case if running on Google Colab, but in case you are running on your own machine, the recommended approach is to download the TensorFlow Serving [Docker image](https://www.tensorflow.org/tfx/serving/setup) rather than installing it.\n",
        "\n",
        "https://keras.io/examples/keras_recipes/tf_serving/"
      ],
      "metadata": {
        "id": "unIHSBlJAq27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install TensorFlow Serving"
      ],
      "metadata": {
        "id": "TQg5E5cjICqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "!wget --output-document - https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!apt-get update && apt-get install tensorflow-model-server"
      ],
      "metadata": {
        "id": "E9k0CfnpIF-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a pretrained image classification model\n",
        "\n",
        "Let's load the updated [MobileNet](https://arxiv.org/abs/1704.04861) model to serve as our example.\n",
        "\n",
        "First, some imports:"
      ],
      "metadata": {
        "id": "7bGo9xGgAlZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkYrCvM8AhW6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can load the pretrained model from Keras [Applications](https://keras.io/api/applications/mobilenet/#mobilenetv2-function)."
      ],
      "metadata": {
        "id": "qRRa9KnpIlnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.applications.MobileNetV2()"
      ],
      "metadata": {
        "id": "zHswG3dQA3cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the human readable class name (and not just the class number), we have to use the `decode_predictions` function for the model we have chosen:"
      ],
      "metadata": {
        "id": "Z9-tKXgEA_iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert scores to label\n",
        "def postprocess(prediction):\n",
        "\n",
        "    label = keras.applications.mobilenet_v2.decode_predictions(prediction, top=1)[0][0][1]\n",
        "\n",
        "    return label"
      ],
      "metadata": {
        "id": "vTpllF6GKV0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose a test image\n",
        "\n",
        "Here is one on the images from the ImageNet dataset. You can choose any other image that you like."
      ],
      "metadata": {
        "id": "NpCCclgqKj-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O testimg.jpg https://raw.githubusercontent.com/larq/zoo/master/tests/fixtures/elephant.jpg"
      ],
      "metadata": {
        "id": "0Y9_CvPsK1wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have a look at the image:"
      ],
      "metadata": {
        "id": "SHq9fNCLNpPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_img = plt.imread(\"testimg.jpg\")\n",
        "print(f\"Original image shape: {sample_img.shape}\")\n",
        "print(f\"Original image pixel range: ({sample_img.min()}, {sample_img.max()})\")\n",
        "plt.imshow(sample_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uvP_iJRGNjm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we read in the image as a numpy array. The shapes must match what the model expects, which for MobileNet is (224, 224) pixels. The Keras utility functions help us resize easily."
      ],
      "metadata": {
        "id": "JzuJm0a6Nr_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = keras.utils.load_img('testimg.jpg', target_size=(224, 224))\n",
        "test_img = keras.utils.img_to_array(test_img)"
      ],
      "metadata": {
        "id": "dK6uO9xFLKbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply preprocessing\n",
        "\n",
        "Remember that the pretrained image models have different ways of preprocessing the input, and we need to choose the corresponding function.\n",
        "\n",
        "As part of our preprocessing we also add the batch dimension, since the model always expects batches of inputs."
      ],
      "metadata": {
        "id": "iF4q3iv3LNZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_img = keras.applications.mobilenet_v2.preprocess_input(test_img)\n",
        "\n",
        "print(f\"Preprocessed image shape: {preprocessed_img.shape}\")\n",
        "print(\n",
        "    f\"Preprocessed image pixel range: ({preprocessed_img.min()},\",\n",
        "    f\"{preprocessed_img.max()})\",\n",
        ")\n",
        "\n",
        "batched_img = tf.expand_dims(preprocessed_img, axis=0)\n",
        "batched_img = tf.cast(batched_img, tf.float32)\n",
        "print(f\"Batched image shape: {batched_img.shape}\")\n",
        "\n",
        "model_outputs = model(batched_img)\n",
        "print(f\"Model output shape: {model_outputs.shape}\")\n",
        "print(f\"Predicted class: {postprocess(model_outputs)}\")\n"
      ],
      "metadata": {
        "id": "i2UJ94eeBHts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems to work when running interactively -- now, let's serve the model as a REST API."
      ],
      "metadata": {
        "id": "H10717ssORuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Serve the model\n",
        "\n",
        "To start TensorFlow Serving, we need to save the model to file."
      ],
      "metadata": {
        "id": "B36LPxAkBQuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "0F3zT9IvVCDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = Path(\"./model\").resolve()\n",
        "model_version = 1\n",
        "model_export_path = model_dir / str(model_version)\n",
        "\n",
        "model.export(model_export_path)\n",
        "\n",
        "print(f\"SavedModel files: {os.listdir(model_export_path)}\")"
      ],
      "metadata": {
        "id": "q44siXyWBTMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check that the save files have the expected inputs and outputs by running the following:"
      ],
      "metadata": {
        "id": "MNtszCMKYfSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli show --dir {model_export_path} --tag_set serve --signature_def serving_default"
      ],
      "metadata": {
        "id": "pYvAVC3DTyxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we export the saved model directory as an environment variable, just so the server can pick it up."
      ],
      "metadata": {
        "id": "VXMxggpqBYyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MODEL_DIR\"] = f\"{model_dir}\""
      ],
      "metadata": {
        "id": "7QNunZzgDav1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, start the server instance in the background, and keep it running.\n",
        "\n",
        "Some hacks involved here (like `nohup`) -- these are required for keeping it running in the notebook, after we move to the next cel.."
      ],
      "metadata": {
        "id": "2K5ogo7UO0K3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg\n",
        "nohup tensorflow_model_server \\\n",
        "  --port=8500 \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=model \\\n",
        "  --model_base_path=$MODEL_DIR >server.log 2>&1"
      ],
      "metadata": {
        "id": "leWtZTf3DfXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can have a look at the server logs to see what is going on.\n",
        "\n",
        "You should see\n",
        "```\n",
        "[evhttp_server.cc : 250] NET_LOG: Entering the event loop ...\n",
        "```\n",
        "at the end -- if not, wait a second and try again."
      ],
      "metadata": {
        "id": "AjTQAMb5PPf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat server.log"
      ],
      "metadata": {
        "id": "kGUHo_VgDhvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also check if TensorFlow is listening to our requests:"
      ],
      "metadata": {
        "id": "2g_XWpRJPgQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo lsof -i -P -n | grep LISTEN"
      ],
      "metadata": {
        "id": "5Q7Udc5eDlgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a request to your model in TensorFlow Serving\n",
        "\n",
        "For the exicting part, let's finally make a request to our service. Requests have to be in JSON format, and contain our data under `\"instances\"`.\n",
        "\n",
        "The request can contain several different configuration parameters, so in case you are serving different models at the same time, the request can contain the model name and switch between them. For all the details on this, have a look at the [documentation](https://www.tensorflow.org/tfx/guide)."
      ],
      "metadata": {
        "id": "XwYAxpozDoPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the request in JSON format\n",
        "data = json.dumps(\n",
        "    {\n",
        "        \"signature_name\": \"serving_default\",\n",
        "        \"instances\": batched_img.numpy().tolist(),  # The image data must be native Python list\n",
        "    }\n",
        ")\n",
        "url = \"http://localhost:8501/v1/models/model:predict\"\n",
        "\n",
        "# Print to see what we will send\n",
        "print(data)"
      ],
      "metadata": {
        "id": "Tm9QiABEDulY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now define the function that sends the `POST` request to our server. The responce will contain a field \"predictions\", which is of course what we are interested in."
      ],
      "metadata": {
        "id": "--W36NGiRe2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rest(json_data, url):\n",
        "\n",
        "    json_response = requests.post(url, data=json_data)\n",
        "    response = json.loads(json_response.text)\n",
        "    rest_outputs = np.array(response[\"predictions\"])\n",
        "\n",
        "    return rest_outputs"
      ],
      "metadata": {
        "id": "tWDJOjmIRd_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try it out:"
      ],
      "metadata": {
        "id": "U5EufhdhSDs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_outputs = predict_rest(data, url)\n",
        "\n",
        "print(f\"REST output shape: {rest_outputs.shape}\")\n",
        "print(f\"Predicted class: {postprocess(rest_outputs)}\")\n"
      ],
      "metadata": {
        "id": "6UQs0EXNDwEs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}