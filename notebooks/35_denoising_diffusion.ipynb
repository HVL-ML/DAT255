{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC9HGXvUidqa"
      },
      "source": [
        "# Denoising diffusion probabilistic model (DDPM)\n",
        "\n",
        "For our last notebook we will train a denoising diffusion probabilistic model, arguably the first big success of the diffusion-type models. Other variants exist too, but are still based on the same concept, of gradually adding noise to an image while trying to learn the inverse process.\n",
        "\n",
        "This notebook follows closely the text of chapter 17 in the textbook, so it's a good idea to read it at the same time as going through the code. Again we present this just as a tutorial, without any extra exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-GFqpsWkdad"
      },
      "source": [
        "First the usual imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANLTBMmgOeH4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.rcParams.update({'font.size': 22})\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SpZoYUMkhcH"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "For this test we pick the usual MNIST images. While they are very small, both training the diffusion model and generating new images is computationally heavy, so using a GPU is strongly recommended.\n",
        "\n",
        "Optionally, you can give it a go on the Fashion MNIST data instead, by just uncommenting the relevant lines below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bLTHWhyPvk4",
        "outputId": "ed4dbfb9-f42e-4f3e-f832-a2422a0a6a92"
      },
      "outputs": [],
      "source": [
        "# Fashion MNIST data\n",
        "#mnist_data = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Handwritten digits\n",
        "mnist_data = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Download\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist_data\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPuAGGXulAlA"
      },
      "source": [
        "## Variance scheduling\n",
        "\n",
        "Plot figure 17-21, showing how we schedule the noise variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exNdvRhVOmmc",
        "outputId": "f7713c9e-5439-4d04-b4ac-b866b2752bc9"
      },
      "outputs": [],
      "source": [
        "def variance_schedule(T, s=0.008, max_beta=0.999):\n",
        "    t = np.arange(T + 1)\n",
        "    f = np.cos((t / T + s) / (1 + s) * np.pi / 2) ** 2\n",
        "    alpha = np.clip(f[1:] / f[:-1], 1 - max_beta, 1)\n",
        "    alpha = np.append(1, alpha).astype(np.float32)  # add α₀ = 1\n",
        "    beta = 1 - alpha\n",
        "    alpha_cumprod = np.cumprod(alpha)\n",
        "    print('alpha:', alpha)\n",
        "    return alpha, alpha_cumprod, beta  # αₜ , α̅ₜ , βₜ for t = 0 to T\n",
        "\n",
        "def linear_schedule(T, s=0.008, max_beta=0.999):\n",
        "    step_scale = 0.005\n",
        "    t = np.arange(T + 1)\n",
        "    f = 1 - step_scale*t / T\n",
        "    alpha = np.clip(f, 1 - max_beta, 1)\n",
        "    alpha = np.append(1, alpha).astype(np.float32)  # add α₀ = 1\n",
        "    beta = 1 - alpha\n",
        "    alpha_cumprod = np.cumprod(alpha)\n",
        "    return alpha, alpha_cumprod, beta  # αₜ , α̅ₜ , βₜ for t = 0 to T\n",
        "\n",
        "np.random.seed(42)  # For reproducibility\n",
        "T = 4000\n",
        "\n",
        "alpha, alpha_cumprod, beta = variance_schedule(T)\n",
        "lin_alpha, lin_alpha_cumprod, lin_beta = linear_schedule(T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "1V_lO_w5Opdn",
        "outputId": "fd83dcb4-3a57-43cc-ecd5-470d92c91e7d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(alpha_cumprod, \"b\", label=r\"$\\bar{\\alpha}_t$ (cosine)\")\n",
        "plt.plot(lin_alpha_cumprod, \"r\", label=r\"$\\bar{\\alpha}_t$ (linear)\")\n",
        "plt.axis([0, T, 0, 1])\n",
        "plt.xlabel(r\"t\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCrnfQ-Bm_Kk"
      },
      "source": [
        "## Prepare data for training\n",
        "\n",
        "Let's define the function for preparing a single batch of noisy training images. Note that because we were clever and wrote out the shortcut in equation 17-6 in the textbook, we don't need to sequentially add the noise up to a given time step $t$, but we can compute it directly from the original input image. Hence we can just pick time steps at random."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w31hNCB2OrzC"
      },
      "outputs": [],
      "source": [
        "def prepare_batch(X):\n",
        "\n",
        "    # Scale the images to have pixel values from -1 to 1\n",
        "    X = tf.cast(X[..., tf.newaxis], tf.float32) * 2 - 1\n",
        "    X_shape = tf.shape(X)\n",
        "\n",
        "    # Select time steps at random\n",
        "    t = tf.random.uniform([X_shape[0]], minval=1, maxval=T + 1, dtype=tf.int32)\n",
        "\n",
        "    # Apply the alpha (noise variance) schedule we computed before\n",
        "    alpha_cm = tf.gather(alpha_cumprod, t)\n",
        "    alpha_cm = tf.reshape(alpha_cm, [X_shape[0]] + [1] * (len(X_shape) - 1))\n",
        "\n",
        "    # Sample noise from a normal distribution\n",
        "    noise = tf.random.normal(X_shape)\n",
        "\n",
        "    # Return a dict with noisy images, and the time step t\n",
        "    return {\n",
        "        \"X_noisy\": alpha_cm ** 0.5 * X + (1 - alpha_cm) ** 0.5 * noise,\n",
        "        \"time\": t,\n",
        "    }, noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nat8v59vowbJ"
      },
      "source": [
        "Here we create TensorFlow datasets containing training and validation images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9TlgOamOtvC"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(X, batch_size=32, shuffle=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(X)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(10_000)\n",
        "    return ds.batch(batch_size).map(prepare_batch).prefetch(1)\n",
        "\n",
        "train_set = prepare_dataset(X_train, batch_size=32, shuffle=True)\n",
        "valid_set = prepare_dataset(X_valid, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqrjydhVpD5V"
      },
      "source": [
        "Before we get started with the training, let's plot the noisy images to see what the model will be predicting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp2s3BM7QTeb"
      },
      "outputs": [],
      "source": [
        "def plot_multiple_images(images, n_cols=None, update=False):\n",
        "\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "    if images.shape[-1] == 1:\n",
        "        images = images.squeeze(axis=-1)\n",
        "\n",
        "    fig = plt.figure(figsize=(n_cols, n_rows))\n",
        "\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    if update:\n",
        "        clear_output(wait=True)\n",
        "        display(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "gIAsa9UoOwBS",
        "outputId": "e98d090d-df12-4a55-befd-e5131bd20a7a"
      },
      "outputs": [],
      "source": [
        "def subtract_noise(X_noisy, time, noise):\n",
        "    X_shape = tf.shape(X_noisy)\n",
        "    alpha_cm = tf.gather(alpha_cumprod, time)\n",
        "    alpha_cm = tf.reshape(alpha_cm, [X_shape[0]] + [1] * (len(X_shape) - 1))\n",
        "    return (X_noisy - (1 - alpha_cm) ** 0.5 * noise) / alpha_cm ** 0.5\n",
        "\n",
        "X_dict, Y_noise = list(train_set.take(1))[0]  # get the first batch\n",
        "X_original = subtract_noise(X_dict[\"X_noisy\"], X_dict[\"time\"], Y_noise)\n",
        "\n",
        "print(\"Original images\")\n",
        "plot_multiple_images(X_original[:8].numpy())\n",
        "plt.show()\n",
        "print(\"Time steps:\", X_dict[\"time\"].numpy()[:8])\n",
        "print(\"Noisy images\")\n",
        "plot_multiple_images(X_dict[\"X_noisy\"][:8].numpy())\n",
        "plt.show()\n",
        "print(\"Noise to predict\")\n",
        "plot_multiple_images(Y_noise[:8].numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lFBErUPpyci"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "The model predicting the reverse diffusion process can basically be anything, as long as the input and output images are the same dimensions. But, for best  results, we also take as input the timestep number, to allow the model to apply different transformations depending on how far in the denoising process we have come.\n",
        "\n",
        "The original DDPM papers use an U-Net architecture, which we already know from the image segmentation model in notebook 11. Before we get to the U-Net part, let's encode the timestep number. Following the original DDPM implementation, we use the same _sinusoidal encodings_ that were used in the transformer paper, _Attention is all you need_. Basically we build a fixed (i.e. not learned) embedding space using sin- and cos-values of the time step number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiTCcL1gOyW0"
      },
      "outputs": [],
      "source": [
        "embed_size = 64\n",
        "\n",
        "class TimeEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, T, embed_size, dtype=tf.float32, **kwargs):\n",
        "        super().__init__(dtype=dtype, **kwargs)\n",
        "        assert embed_size % 2 == 0, \"embed_size must be even\"\n",
        "        p, i = np.meshgrid(np.arange(T + 1), 2 * np.arange(embed_size // 2))\n",
        "        t_emb = np.empty((T + 1, embed_size))\n",
        "        t_emb[:, ::2] = np.sin(p / 10_000 ** (i / embed_size)).T\n",
        "        t_emb[:, 1::2] = np.cos(p / 10_000 ** (i / embed_size)).T\n",
        "        self.time_encodings = tf.constant(t_emb.astype(self.dtype))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.gather(self.time_encodings, inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rND5J8w0rT1y"
      },
      "source": [
        "Now for the model itself. Recall that the U-Net architecture consists of a downsampling part followed by an upsampling part, with residual connections between each downsampling layer and the corresponding upsampling layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUSXCPQTO2Zn"
      },
      "outputs": [],
      "source": [
        "def build_diffusion_model():\n",
        "    X_noisy = tf.keras.layers.Input(shape=[28, 28, 1], name=\"X_noisy\")\n",
        "    time_input = tf.keras.layers.Input(shape=[], dtype=tf.int32, name=\"time\")\n",
        "    time_enc = TimeEncoding(T, embed_size)(time_input)\n",
        "\n",
        "    dim = 16\n",
        "    Z = tf.keras.layers.ZeroPadding2D((3, 3))(X_noisy)\n",
        "    Z = tf.keras.layers.Conv2D(dim, 3)(Z)\n",
        "    Z = tf.keras.layers.BatchNormalization()(Z)\n",
        "    Z = tf.keras.layers.Activation(\"relu\")(Z)\n",
        "\n",
        "    time = tf.keras.layers.Dense(dim)(time_enc)  # adapt time encoding\n",
        "    Z = time[:, tf.newaxis, tf.newaxis, :] + Z  # add time data to every pixel\n",
        "\n",
        "    skip = Z\n",
        "    cross_skips = []  # skip connections across the down and up parts of the UNet\n",
        "\n",
        "    for dim in (32, 64, 128):\n",
        "        Z = tf.keras.layers.Activation(\"relu\")(Z)\n",
        "        Z = tf.keras.layers.SeparableConv2D(dim, 3, padding=\"same\")(Z)\n",
        "        Z = tf.keras.layers.BatchNormalization()(Z)\n",
        "\n",
        "        Z = tf.keras.layers.Activation(\"relu\")(Z)\n",
        "        Z = tf.keras.layers.SeparableConv2D(dim, 3, padding=\"same\")(Z)\n",
        "        Z = tf.keras.layers.BatchNormalization()(Z)\n",
        "\n",
        "        cross_skips.append(Z)\n",
        "        Z = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(Z)\n",
        "        skip_link = tf.keras.layers.Conv2D(dim, 1, strides=2,\n",
        "                                           padding=\"same\")(skip)\n",
        "        Z = tf.keras.layers.add([Z, skip_link])\n",
        "\n",
        "        time = tf.keras.layers.Dense(dim)(time_enc)\n",
        "        Z = time[:, tf.newaxis, tf.newaxis, :] + Z\n",
        "        skip = Z\n",
        "\n",
        "    for dim in (64, 32, 16):\n",
        "        Z = tf.keras.layers.Activation(\"relu\")(Z)\n",
        "        Z = tf.keras.layers.Conv2DTranspose(dim, 3, padding=\"same\")(Z)\n",
        "        Z = tf.keras.layers.BatchNormalization()(Z)\n",
        "\n",
        "        Z = tf.keras.layers.Activation(\"relu\")(Z)\n",
        "        Z = tf.keras.layers.Conv2DTranspose(dim, 3, padding=\"same\")(Z)\n",
        "        Z = tf.keras.layers.BatchNormalization()(Z)\n",
        "\n",
        "        Z = tf.keras.layers.UpSampling2D(2)(Z)\n",
        "\n",
        "        skip_link = tf.keras.layers.UpSampling2D(2)(skip)\n",
        "        skip_link = tf.keras.layers.Conv2D(dim, 1, padding=\"same\")(skip_link)\n",
        "        Z = tf.keras.layers.add([Z, skip_link])\n",
        "\n",
        "        time = tf.keras.layers.Dense(dim)(time_enc)\n",
        "        Z = time[:, tf.newaxis, tf.newaxis, :] + Z\n",
        "        Z = tf.keras.layers.concatenate([Z, cross_skips.pop()], axis=-1)\n",
        "        skip = Z\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(1, 3, padding=\"same\")(Z)[:, 2:-2, 2:-2]\n",
        "\n",
        "    return tf.keras.Model(inputs=[X_noisy, time_input], outputs=[outputs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wlpCH0Ar2IJ"
      },
      "source": [
        "Train the model!\n",
        "\n",
        "The loss function should compare the pixel-wise differences between the true and predicted denoised image. We could choose mean squared error (MSE), mean absolute error (MAE, which according to the DDPM paper works better), or we could do like the textbook and use a combination, which would be the Huber loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFyjBau_O4wf",
        "outputId": "4b37d895-ef8b-4d4e-8b6a-ca40deb6d683"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = build_diffusion_model()\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.Huber(),\n",
        "    optimizer=tf.keras.optimizers.Nadam()\n",
        ")\n",
        "\n",
        "# Add a ModelCheckpoint callback\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"my_diffusion_model.keras\",\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_set,\n",
        "    validation_data=valid_set,\n",
        "    epochs=50,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAzqG-57szGP"
      },
      "source": [
        "## Generate new images\n",
        "\n",
        "With the trained model in place, we can finally generate new images.\n",
        "\n",
        "We sample random values as a starting point, and then sequentially denoise them. Note that this takes a while, since we are running the model 4000 times to generate a single image!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "eKOO4DnAO6zJ",
        "outputId": "499d2b58-eb16-4e20-a5d9-bdb6e5e540fc"
      },
      "outputs": [],
      "source": [
        "def generate(model, batch_size=32, show_step_interval=200):\n",
        "    X = tf.random.normal([batch_size, 28, 28, 1])\n",
        "    for t in range(T - 1, 0, -1):\n",
        "        print(f\"\\rt = {t}\", end=\" \")  # extra code – show progress\n",
        "        noise = (tf.random.normal if t > 1 else tf.zeros)(tf.shape(X))\n",
        "        X_noise = model({\"X_noisy\": X, \"time\": tf.constant([t] * batch_size)})\n",
        "        X = (\n",
        "            1 / alpha[t] ** 0.5\n",
        "            * (X - beta[t] / (1 - alpha_cumprod[t]) ** 0.5 * X_noise)\n",
        "            + (1 - alpha[t]) ** 0.5 * noise\n",
        "        )\n",
        "\n",
        "        # Show the denoising process\n",
        "        if (t % show_step_interval == 0) or (t == 1):\n",
        "            plot_multiple_images(X.numpy(), 8, update=True)\n",
        "            plt.show()\n",
        "\n",
        "    return X\n",
        "\n",
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on the CPU\n",
        "X_gen = generate(model)  # generated images\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKFSGMqct0tA"
      },
      "source": [
        "Plot the final output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "SPFmi1jeO9MX",
        "outputId": "4aa9398a-451f-47a2-d15d-6ff019471cac"
      },
      "outputs": [],
      "source": [
        "plot_multiple_images(X_gen.numpy(), 8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncwuCkxdVvpu"
      },
      "source": [
        "Note that the quality of the results are very dependent on how long we train the model for, so if you want to improve it, try running for more epochs."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
