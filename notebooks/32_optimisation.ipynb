{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model size optimisation with LiteRT\n",
        "\n",
        "In this notebook we will try to minimise our model size, in terms of both memory use and stored file size, using what is called _post-training quantisation_.\n",
        "\n",
        "This means first training a model using full `float32` precision for the weights, and then converting them to 8-bit integers.\n",
        "\n",
        "For all the details and more options for quantisation, have a look at the LiteRT documentation:\n",
        "https://ai.google.dev/edge/litert/models/post_training_quantization."
      ],
      "metadata": {
        "id": "c-XvMI3C94j0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "kOaeSgq9-EWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKrS-bZ675EP"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model\n",
        "\n",
        "Let's train a simple MNIST model to serve as our example."
      ],
      "metadata": {
        "id": "Cdy-rFK5-HKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, test_labels)\n",
        ")"
      ],
      "metadata": {
        "id": "68Qt67LZ-JzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert the model to LiteRT format\n",
        "\n",
        "Converting to the optimised LiteRT format is quite simple -- we need just to call a `converter`-"
      ],
      "metadata": {
        "id": "CFQcEucZ-Oyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "z1rCJGCz-TKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save it the converted model, without applying quantisation."
      ],
      "metadata": {
        "id": "30mQgh6g-VPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_models_dir = pathlib.Path(\"mnist_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
      ],
      "metadata": {
        "id": "4DGsI2F3-ZMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "metadata": {
        "id": "bHAVqWBr-Zyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantise the model\n",
        "\n",
        "Now, let's quantise all the parameters, using the `DEFAULT` strategy. This is a again just a matter of calling the `converter`, but we first add the optimisation strategy.\n",
        "Quantise it"
      ],
      "metadata": {
        "id": "htkIXa_i-dqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set optimisation strategy\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Convert and save\n",
        "tflite_quant_model = converter.convert()\n",
        "tflite_model_quant_file = tflite_models_dir/\"mnist_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)"
      ],
      "metadata": {
        "id": "TeIiV97j-e6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the file sizes:"
      ],
      "metadata": {
        "id": "ITjNKm9f-hyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! du -h {tflite_models_dir}/*"
      ],
      "metadata": {
        "id": "y9q2s_fw-jdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's almost a 1/4 reduction in size -- not bad for very little work.\n",
        "\n",
        "Of course, we should check that we are not loosing prediction performance. Time to run the models."
      ],
      "metadata": {
        "id": "5mszM0iffiWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the optimised models"
      ],
      "metadata": {
        "id": "fneofZaF-lsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running LiteRT models is a little differnt than a regular Keras one. In particular, we need an `Interpreter` to interface the model with its inputs and outputs."
      ],
      "metadata": {
        "id": "wwZM4aMrf3E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The original model\n",
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()"
      ],
      "metadata": {
        "id": "1GYzX71S_1Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The quantised model\n",
        "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
        "interpreter_quant.allocate_tensors()"
      ],
      "metadata": {
        "id": "5oO7I4AE_25c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load a test image, and predict:"
      ],
      "metadata": {
        "id": "VsYKZotTgRWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "interpreter.set_tensor(input_index, test_image)\n",
        "interpreter.invoke()\n",
        "predictions = interpreter.get_tensor(output_index)"
      ],
      "metadata": {
        "id": "iCQ0gPTs-o1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "\n",
        "plt.imshow(test_images[0])\n",
        "template = \"True:{true}, predicted:{predict}\"\n",
        "_ = plt.title(template.format(true= str(test_labels[0]),\n",
        "                              predict=str(np.argmax(predictions[0]))))\n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "eFEzRrYr-qBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare accuracies\n",
        "\n",
        "Run over all the test images, and see how the quantised model compares to the non-quantised one.\n",
        "\n",
        "First define a function to compute test accuracy"
      ],
      "metadata": {
        "id": "DDSPav9f-wML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A helper function to evaluate the LiteRT model using \"test\" dataset.\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for test_image in test_images:\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  accurate_count = 0\n",
        "  for index in range(len(prediction_digits)):\n",
        "    if prediction_digits[index] == test_labels[index]:\n",
        "      accurate_count += 1\n",
        "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "_jgqfYsB-xpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The run it:"
      ],
      "metadata": {
        "id": "Jfuzts0UhNAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate_model(interpreter))\n",
        "print(evaluate_model(interpreter_quant))"
      ],
      "metadata": {
        "id": "abYD7p9G-zI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}