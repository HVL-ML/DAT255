{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c987d0f4-c7c9-4f61-9bfd-f755de44d150",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01484d9f-6cd7-47e1-849d-e1fb75820e60",
   "metadata": {},
   "source": [
    "A simple example of speech recognition using OpenAI's Whisper model. During the course, we'll learn about how such models work, and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c2af0-d544-4524-a9eb-621253023914",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69056cb-5256-4957-b05a-ca75cbde6a03",
   "metadata": {},
   "source": [
    "We use the ðŸ¤— Transfomers library: https://huggingface.co/docs/transformers/index and the Whisper model from OpenAI: https://openai.com/blog/whisper/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b759b7-9250-477e-ae92-55ea92473673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae90053-8faf-48f6-922a-84efd675c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54060f37-55c7-47c3-b7d7-e7081da0c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d1b09-a013-4a88-bf83-ddf840d1f200",
   "metadata": {},
   "source": [
    "# Setup model and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37c7e7-3b94-4dea-a486-7fa6c8c1d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/whisper-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6034ca-67f6-4bf0-9318-5dec33a51656",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f5f15-7e5e-44ab-924e-e74806a2c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=model_name,\n",
    "    chunk_length_s=30,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc32e38-3133-40d2-b2d4-bc797fd57d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pipe(\"audio.ogg\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d84cd-9df8-4dc6-aaef-6af45051e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ba374-2fec-4f34-b662-0022e3f5c84c",
   "metadata": {},
   "source": [
    "# A simple application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067ea1b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5b60a-a8a8-4040-9d78-cee9d683747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ddcd2-ef58-4f7e-a83f-12f937a6953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio):\n",
    "    transcription = pipe(audio)[\"text\"]\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe31a0be-ed53-40f9-8bcc-b25ba19fc846",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    [\"audio.ogg\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb01a876",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f18ec7-6a1e-41e1-9208-cfa0698d136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(\n",
    "    title = 'OpenAI Whisper', fn=transcribe, \n",
    "    inputs=[\n",
    "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
    "    ],\n",
    "    outputs=[\"textbox\"],\n",
    "    examples=examples).launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
